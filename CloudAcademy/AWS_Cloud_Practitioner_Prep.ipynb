{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74bdbeea-b099-4c83-bd5e-706289077f4a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# AWS Cloud Practitioner Certification Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d352613-7b5f-4fda-bf1e-347879e697ba",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## AWS Certified Cloud Practitioner Domains\n",
    "1. Cloud Concepts\n",
    "    * Define the AWS cloud and its value proposition\n",
    "    * Identify aspects of AWS cloud economics\n",
    "    * List the different cloud architecture design principles\n",
    "2. Security and Compliance\n",
    "    * Define the AWS shared responsibility model\n",
    "    * Define AWS cloud security and compliance concepts\n",
    "    * Identify AWS access management capabilities\n",
    "    * Identify resources for security support\n",
    "3. Technology\n",
    "    * Define methods of deploying & operating in the AWS cloud\n",
    "    * Define the AWS global infrastructure\n",
    "    * Identify the core AWS services\n",
    "    * Idenitify resources for technology support\n",
    "4. Billing and Pricing\n",
    "    * Compare and contrast the various pricing models for AWS\n",
    "    * Recognize the various account structures in relation to AWS billing and pricing\n",
    "    * Identify resources available for billing support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d2d4f8-ce5d-4d42-ba4d-58443d625b8f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## What is Cloud Computing?\n",
    "\n",
    "**Goal 1** - comprehensive understanding of Cloud Computing along with key concepts and benefits  \n",
    "**Goal 2** - when Cloud computing should be used and which model and service to deploy  \n",
    "\n",
    "1. What is Cloud Computing?\n",
    "    * **Cloud Computing** is a remote virtual pool of on-demand shared resources offering Compute, Storage, Database and Network services that can be rapidly deployed at scale\n",
    "    * **Virtualization** - allows the possibility of having multiple virtual machines (VMs) each running essentially seperate operating system and applications, installed on 1 physical server\n",
    "    * **Hypervisor** - a piece of software used to create the virtual environment allowing for multiple VMs to be installed on the same host. Shared hardware is achieved through a hypervisor. VMs make requests to the hardware via the hypervisor which ensures that the resources are shared between the VMs as needed and configured.\n",
    "    * Benefits of virtualization:\n",
    "        1. reduced capital expenditure (less hardware required)\n",
    "        2. reduced operating costs (less resources required for hardware)\n",
    "        3. smaller footprint (less physical space necessary)\n",
    "        4. optimization of resources\n",
    "    * Basic Cloud Resources:\n",
    "        1. **Compute** resources: brains to process your workload\n",
    "        2. **Storage** resources: allows data to be saved\n",
    "        3. **Database** resources: store structured sets of data used by applications\n",
    "        4. **Network** resources: provide connectivity that allows resources to communicate\n",
    "2. Cloud Deployment Models\n",
    "    1. **Public** vendor makes use of shared infrastructure that can be provisioned on demand and accessed over the internet for public usage. the consumer is typically unaware of the hardware and exact location of the data while the vendor provides all the backend and physical maintenance\n",
    "    2. **Private** the infrastructure is privately hosted and managed by the individual company using it. hardware typically lives on premesis\n",
    "    3. **Hybrid** makes use of both public and private clouds. established when a network link is configured between the private and public clouds. typically short-term configurations (e.g. for test/dev purposes)\n",
    "3. Key Cloud COncepts\n",
    "    * **On-demand Resourcing** resources are available almost immediately\n",
    "    * **Scalability** rapidly scale an environment both up/down and in/out. **Vertical Scaling** - increasing or decreasing compute resources on demand.\n",
    "    * **Economy of Scale** exceptionally low resource costs copared t traditional hosting\n",
    "    * **Flexibility and Elasticity** can fully customize the amount, quantity, duration and scale of the resources in your environment\n",
    "    * **Growth** your organization can experience growth that paces with need with far fewer constraints than classic on-premisis approaches\n",
    "    * **Utility Based Metering** you only pay for what you use\n",
    "    * **Shared Infrastructure** reduces overhead\n",
    "    * **Highly Available** replicatable & reusable\n",
    "    * **Security** more secure than on-site data centers see: Shared Responsibility Model\n",
    "4. Cloud Service Models\n",
    "    * **IaaS** - Infrastructure as a Service - a service that allows you to architect your own portion of the cloud (ex: AWS)\n",
    "    * **PaaS** - Platform as a Service - access to a framework from the operating system and up (ex: Heroku)\n",
    "    * **SaaS** - Software as a Service - allows for the delivery of an application that can be widely distributed (ex: GMail)\n",
    "    * Other models: Disaster Recovery as a Service, Communications as a Service, Monitoring as a Service\n",
    "5. Common use cases of Cloud COmputing\n",
    "    * Migrating locally existing production services to the Cloud\n",
    "    * Traffic bursting - dealing with fluctuations on data resources\n",
    "    * Backup/ Data redundancy at a lower cost\n",
    "    * Web Hosting takes out a lot of administrative and maintenance demands\n",
    "    * Test/Dev environments can spin up instances as/when needed and then shut down when finished\n",
    "    * Proof of Concept work becommes more feasible\n",
    "    * Big Data & Data manipulation the cloud scales to large data better\n",
    "6. How Data Center architecture is reflected within the cloud\n",
    "    * classic datacenter: location. physical security, mech/electric infrastructure, network infrastructure, servers, storage\n",
    "    * how are these components reflected in the cloud?\n",
    "        * location: cloud providers have different regions with built in redundancy\n",
    "        * physical security: vender secures the data center while end user has no physical access to where data is stored\n",
    "        * mech/electrical infrastructure: maintained by the vender\n",
    "        * network infrastructure: operates at a software level in the Cloud, not physical devices like switches or routers\n",
    "        * servers: instances or virtual machines\n",
    "        * storage: often regarded as unlimited, hugely scalable. AWS has the Elastic Block Store service\n",
    "        \n",
    "7. Summary\n",
    "    * Cloud Computing is a remote virtual pool of on-demand shared resources offering Compute, Storage, Database and Network services that can be rapidly deployed at scale\n",
    "    * Main concepts: on-demand resources, scalability, economy of sclae, felxibility and elasticity, utility based metering, shared infrastructure, highly available, security\n",
    "    * 3 Main cloud service models: IaaS, PaaS, SaaS\n",
    "    * 3 Cloud Deployment Models: public, private, hybrid\n",
    "    * a variety of use cases such as: web hosting, big data manipulation, traffic bursting etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252cd48f-a2c8-4da0-a663-748a48e5029c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Compute Fundamentals for AWS\n",
    "\n",
    "AWS Foundation Services\n",
    "* Compute\n",
    "* Storage\n",
    "* Database\n",
    "* Network\n",
    "\n",
    "This course will focus on the foundational Comute resources. \n",
    "\n",
    "1. What is 'Compute' in AWS?\n",
    "    * **Compute resources** can be considered the brains and processing power required by applications and systems to carry out computational tasks via a series of instructions\n",
    "    * Compute resources are closely related to common server coponents such as CPUs and RAM\n",
    "    * a very wide range of compute resources for different uses in AWS: Compute services can be as large as hundreds of EC2 instances continually processing millions of instructions. On the other hand, compute services can utilize just a few hundred miliseconds of resources for a few lines of code in an AWS Lambda\n",
    "    * Compute resources can be consumed in different quantities, for different lengths of time, across a range of categories, offering a wide scope of performance and benefit options\n",
    "    * [Cloud Compute Index](https://aws.amazon.com/products/compute/)\n",
    "2. Elastic Compute Cloud (EC2)\n",
    "    * **EC2** allows you to deploy virtual servers within your AWs environment. Most people will require an EC2 instance within their environment as a part of at least one of their solutions\n",
    "    * The EC2 service can e broken down into the following components:\n",
    "        * **Amazon Machine Images** (AMIs) \n",
    "            - are essentially templates of preconfigured EC2 instances which allow you to quickly launch a new EC2 instance based on the configuration within the AMI.\n",
    "            - an AMI is an image baseline with an operating system and applications along with any custom configuration\n",
    "            - can create AMIs to help speed deployments: Amazon Linux AMI $\\rightarrow$ EC2 instance $\\rightarrow$ Customized instance $\\rightarrow$ Custom AMI $\\rightarrow$ launch multiple instances of the Customized Instance ....very good for autoscaling\n",
    "            - the AWS Marketplace has many customized AMIs for purchase from trusted vendors\n",
    "            - Community AMIs are a repo of AMIs created by other AWS members for community use\n",
    "        * **Instance Types** \n",
    "            - **Instance types** define the size of the instance based on a number of parameters: ECUs - # EC2 compute units, vCPUs - # virtual CPUs on the instance, Physical Processor - processing speed, Memory - amount of memory available, Instance Storage & Network Performance. etc.\n",
    "            - **Instance Families** - instance types that offer distinct performance benefits\n",
    "                - MicroInstances - low-cost with minimal CPU\n",
    "                - General Purpose - have a balanced mix of CPU, storage and memory\n",
    "                - Compute Optimized - have a greater focus on Compute with a high vCPU:memory ratio\n",
    "                - GPU - optimized for graphic intensive processes\n",
    "                - FPGA - filled programmable gate arrays for massively parrallel processes (think genomics)\n",
    "                - Memory optimized - large scale enterprize in memry applications. real time processing of unstructured data\n",
    "                - Storage Optimized - high IO and storage capacity\n",
    "        * **Instance Purchasing Optioons**: \n",
    "            - On-demand instances: can be launched at any time, can be used as long as needed, have a flat per second rate. Suggested use: short-term processes that are unpredictable and can't be interupted. Best for test/dev\n",
    "            - reseerved instances: Purchases for a set period of time for a reduced cost. can pay all upfront, partial upfront, or no upfront (w/diminishing returns). Best applied for long-term predictable workloads. preferred: scheduled instances that are continuously running\n",
    "            - scheduled instances: pay for reservations on a recurring schedule, either daily, weekly or monthly. If you set up a scheduled instance and don't use it, you will still be charged. preferred use: scheduled instances that are not continually running\n",
    "            - spot instances: can bid for unused EC2 compute resources. However, there are no guarentees for a fixed period of time. the price fluctuates based on supply/demand. However, there's a chance you could get a large EC2 instance at a very low price. This option is useful for processing data that can be suddenly interupted (batch jobs and background data processing)\n",
    "            - on-demand capacity reservations: reserve capacity based on different attributes such as instance type, platform and tenancy, within a particular availability zone for any period of time. Can be used on reserved instances.\n",
    "        * **Tendancy** - the physical server within an AWS data center that is the underlying host of your EC2 instance\n",
    "            * **Shared Tenancy** EC2 instance launched on any available host with the required resources. The same host may be used by multiple customers while AWS security mechanisms prevent one EC2 instance from accessing another on the same host\n",
    "            * **Dedicated Instances** EC2 instance hosted on hardware that no other customer can access. May be required to meet compiance. Dedicated instances cost mmore.\n",
    "            * **Dedicated Hosts** Additional visibility and control on the physical host. Allows to use the same host for a number of instances. May be required to meet compliance\n",
    "        * **User Data** - enter commands that will run during the first boot cycle of that instance. EX: perform functions upon boot to pull down additional software or run OS updates\n",
    "        * **Storage Options** - selecting storage for EC2 instances will depend on the instance selected\n",
    "            * Persistent Storage: available by attaching Elastic Block Storage (EBS) volumes. The EBS volumes are seperate entities from the EC2 instance and are attached via the AWS network. analogous to attaching a harddrive to your PC. The process of attaching EBS the data get replicated across multiple volumes for persistence. EBS volumes can be detached from the EC2 and reattched or used with other resourced. can also implement encryption and take backup snapshots of the data for further security\n",
    "            * Ephemeral Storage: created by EC2 instances using local storage. is physically attached to the underlying host. analogous to the hard drive on a PC with the exception that when an EC2 instance is stopped, all saved data on disk is lost. if you reboot the instance, the data will remain intact (unlike google colab). you cannot detach the data fro the instance\n",
    "        * **Security** - will be asked to select a Security Group for your instance. [For more info](https://cloudacademy.com/blog/aws-security-groups-instance-level-security/). At the end of EC2 instance creation, you will need to associate a key pair to the instance. **Key pair** - a public & private key. The purpose of the key pair is to encrypt the login informationn for Linux and Windows EC2 instances, and then decrypt the same information allowing you to authenticate onto the instance. The public key is held and kept by AWS, the private key is the users responsibility to keep and ensure that it is not lost/compromised. It is possible to use the same key pair for multipple instances. It is the user's responsibility to maintain and install the latest OS and security patches as part of the shared responsibility model.\n",
    "        * DEMO. From Console $\\rightarrow$ EC2 $\\rightarrow$ launch instance $\\rightarrow$ go with an AWS linux $\\rightarrow$ General Purpose t2.micro $\\rightarrow$ configure instnace details      \n",
    "3. Elastic Container Service (ECS) - allows you to run Docker-enabled applications packaged as containers across a cluster of EC2 instances. The user does not need to manage their own cluster management system beccause this is abstracted with the ECS service by passing the job to AWS Fargate\n",
    "    * **Docker Containers** holds everything an application needs to run from within its container package (runtime, packages etc) except the OS; this makes container applications very portable. \n",
    "    * With AWS ECS there is no need to install any management or monitoring software for your cluster\n",
    "    * 2 different deployment modes:\n",
    "        * Fargate Launch: reqired to specify the CPU and memory required, define networking and IAM policies, and to package application into containers\n",
    "        * EC2 Launch: much more configurable/customizable. User is responsible for patching and scaling instances, specifying instance type and assigning containers\n",
    "    * Monitoring is taken care of through AWS CloudWatch: can create alarms based on metrics for specific events (e.g. cluster size scaling up/down)\n",
    "    * an ECS cluster is comprised of a collection of EC2 instances that operate much the same way as a single EC2 instance\n",
    "    * clusters act a a resource pool to aggregate CPU, memory etc\n",
    "    * clusters are dynamically scalable and can have multiple instances\n",
    "    * ECS clusters are region specific\n",
    "4. Elastic Container Registry (ECR) - a secure location to store and manage your docker images. This is a fully managed service, so you don't need to provision any infrastructure to allow you to create this registry of docker images. This service allows devs to push/pull and manage their library of docker images in a central and secure location.\n",
    "    * Registry - allows you to host and store docker images as well as create image repositories. Your account will have both read/write access by default to any images you create within the registry and any repository. Access to registry and images can be controlled via IAM policies in addition to repository policies\n",
    "    * Auth token - before your docker cliet can access your registry, it needs to be authenticated as an AWS user via an Authorization token. beginning authorization for a docker client with the default registry: 1) run the `get-login` command using the AWS CLI 2) the output response will be a docker login command 3) the resulting auth token can be used for the next 12hrs\n",
    "    * Repository - objects in the registry that allow you to group together and secure different docker images. one registry can hold mu;tiple repositories allowing the user to organize/manage docker images. IAM and repository policies can be used to manage permissions to each repository\n",
    "    * Repository policy - resource-based policies.\n",
    "        * IAM managed policies: AmazonEC2ContaierRegistryFullAccess, AmazonEC2ContaierRegistryPowerUser, AmazonEC2ContaierRegistryReadOnly\n",
    "        * will need to add a principal to a repo policy to determine who has access/permission. this will require access to the ecr:GetAuthorizationToken API call. Actions a user has can be controlled by repository policies.\n",
    "    * Image - to push an image into ECR use the docker push command; to retrieve an image you can use the docker pull command\n",
    "5. Elastic Container Seervice for Kubernetes (EKS)\n",
    "    * **Kubernetes** - an open-source container orchestration tool designed to automate, deploy, scale and operate containerized applications. it can scale dramatically and is run-time agnostic\n",
    "    * **EKS** - a managed service allowing you to run kubernetes across your AWS infrastructure without having to take care of provisioning and running the kubernetes management infrastructure in a control plane. the user only needs to provision the worker nodes\n",
    "    * **Control plane** - a number of different APIs, the kublet processes and the Kubernetes Master. the control plane schedules containers onto nodes and continually monitors the objects\n",
    "    * In EKS, AWS is responsible for provisioning, scaling, and managing the control plane, and they do this by utilizing multiple availability zones for additional resilience\n",
    "    * **Worker Nodes** - kubernetes clusters are composed of nodes. an aggregates is the collection of nodes. A node is a kubernetes worker machine that runs an on-demand EC2 instance which includes software to run containers. Each node has an associated AMI to ensure Docker and kuberlet installation for security controls. the user provisions the nodes which can then connect to EKS using an endpoint.\n",
    "    * Working with EKS\n",
    "        1. Create an EKS Service Role - an IAM role that allows EKS to provision and configure specific resources. must have AmazonEKSServicePolicy & AmazonEKSClusterPolicy\n",
    "        2. Create an EKS Cluster VPC - a CloudFormation stack configured to use EKS\n",
    "        3. Install kubectl and AWS-IAM authenticator. Kubectl is a command line utility for Kubernetes\n",
    "        4. Create your EKS Cluster\n",
    "        5. Configure kubectl for EKS using the update-kubeconfig command in AWS CLI\n",
    "        6. Provision and configure Worker Nodes. once EKS cluster shows 'active' status, launch using CloudFormation\n",
    "        7. Configure the worker node to join the EKS cluster\n",
    "6. AWS Elastic Beanstalk - takes uploaded code of a web application and automatically provisions and deploys the required resources within AWS to make the web application operational. These resources include EC2, Auto scaling, application health monitoring and elastic load balancing in addition to capacity provisioning. Elastic beanstalk is an ideal service for engineers who may not have the familiarity or the necessary skills within AWS to deploy, provision, monitor and scale the correct environment to run the developed application. AWS Elastic beanstalk deploys the correct infrastructure to run the uploaded code. The user can then support and maintain the environment.\n",
    "    * operates with many platforms and languages: ruby, python, PHP, Node.js, Go Docker things etc.\n",
    "    * Elastic Beanstalk, as a service, is free to use. However, any resources that are created on yur applications behalf (e.g. EC2 instances) will be charged standard billing at the time of deployment.\n",
    "    * Elastic beanstalk core components:\n",
    "        * application version - a very specific reference to a section of deployable code. the application version will typically point to S3 where the code might reside.\n",
    "        * environment - All the resources created by Elastic beanstalk. an application version deployed by AWS resources configured and provisioned by AWS Elastic beanstalk. the app becomes operational within your environment.\n",
    "        * environment configurations - collection of parameters and settings that dictate how an environment willl have its resources provisioned by Elastic Beanstalk and how these resources will behave\n",
    "        * environment tier\n",
    "            * web server environment - if the app manages and handles http requests. typically used for standard web applications that operate and serve requests over HTTP port 80. Typical resources: Route 53, Elastic Load Balancer, Auto Scaling, EC2 & Security Groups\n",
    "            * worker environment - does not run http requests and instead pulls data from an SQS queue. applications that will have a back-end processing task, that will interact with AWS SQS. Typical resources: SQS Queue,  IAM Service Role, Auto Scaling, EC2\n",
    "        * configuration template - provides the baseline for creating a new, unique, environment configuration.\n",
    "        * platform - the culmination of components from the OS of the instance, the programming language, the server type and components of Elastic Beanstalk\n",
    "        * Applications - collection of environments, environment configurations and application versions.\n",
    "    * Elastic beanstalk Workflow\n",
    "        1. Create an Application\n",
    "        2. Upload the Application Version (creates the environment\n",
    "        3. Launch the Environment\n",
    "        4. Manage Environment (deploy new versions)\n",
    "7. AWS Lambda - is a serverless compute service that allows you to run yur application code without having to manage EC2 instances.\n",
    "    * **Serverless** - means that you do not need to worry about provisioning and managing your own compute resources to run your own code, instead this is managed and provisioned by AWS. the service does require compute power to carry out the code requests, but because AWS user does not need to be concerned with managing the compute power or where it's provisioned from, its considered 'serverless' from this perspective\n",
    "    * You only ever have to pay for compute power when Lambda is in use via Lambda Functions. AWS Lambda charges power per 100ms of use when your code is running, in addition to the number of times your code runs.\n",
    "    * **Working with AWS Lambda** \n",
    "        1. upload code to Lambda. Supported languages: Node.js, Java, C#, Python, Go, PowerShell, Ruby\n",
    "        2. Configure your Lambda to execute upon specific triggers from supported event sources. EX: an object being uploaded to an S3 bucket\n",
    "        3. Once the trigger is initiated, Lambda will run your code (as per the Lambda function) using only the required compute power as defined.\n",
    "        4. AWS records the compute time in ms and the quantity of Lambda functions run to ascertain the cost of the service\n",
    "    * **Components of AWS Lambda**\n",
    "        * the Lambda functions - compiled code that you want Lambda to invoke when triggered\n",
    "        * Event sources - AWS services that can be used to trigger your Lambda fxn\n",
    "        * Trigger - operation from an event source that causes the function to invoke. ex: 'put' request in S3\n",
    "        * Downstream Resources - required for execution of the Lambda. these are the resources to be used upon invokation of the function\n",
    "        * Log Streams - help to identify issues and troubleshoot your Lambda fxn recorded in CloudWatch\n",
    "    * Creating lambda Functions\n",
    "        1. Selecting a Blueprint - templates provided by AWS Lambda (ex: S3-get-object)\n",
    "        2. Configure Triggers - define the trigger for the Lambda\n",
    "        3. Configure the Function - upload the code or edit in-line. Define the required resources, max execution timeout, IAM role and Handler Name.\n",
    "    * Benefits: AWS Lambda is highly scalable serverless service couped with fantastic cost optimization compared to EC2 as you are only charged for Compute power while the code is running and for the number of functions called.\n",
    "8. AWS Batch - used to manage and run batch computing workloads within AWS\n",
    "    * **Batch Computing** - used when vast amounts of compute power across a cluster of compute resources is needed to complete batch processing for a series of tasks\n",
    "    * AWS Batch seamlessly creates a cluster of compute resources which are highly scalable taking advantage of the elasticity of AWS coping with any level of batch preocessing whilst optimizing distributed workloads. All provisioning, monitoring, maintenance and management of the clusters is taken care of by AWS\n",
    "    * 5 Components of AWS Batch\n",
    "        1. Jobs - units of work (ex: executable file or an application on an EC2 instance) to be run by AWS Batch. jobs are ru on EC2 instances as containerized applications and can take on different states ( submitted, pending, running, failed etc)\n",
    "        2. Job Definitions - define specific parameters for the jobs themselves and dictate how the job will run and with what configuration. (ex: how many CPUs for the container, what data volumes to use, IAM roles, mount points)\n",
    "        3. Job queues - are scheduled placement of jobs in a job queue until they run. there can be multiple queues with different priorities. can be on-demand or spot.\n",
    "        4. Job Scheduling - the job scheduler takes care of when jobs should be run and from which compute environment\n",
    "        5. Compute environments - contain the compute resources to carry ut the job.\n",
    "            * Managed environments - the service handles provisioning and creates an ECS Cluster\n",
    "            * Unmanaged environments - provisioned by the user for greater customizability (but requires greater administration and maintenance)\n",
    "    * AWS Batch is a great resource if you need to run multiple jobs in parallel\n",
    "9. Amazon Lightsail - essentially a VPS backed by AWS infrastructure, much like an EC2 instance but without as many configurable steps throughout its creation. Commonly used to host simple websites, small applications and blogs. Lightsail provides a lightweight solution for small rpojects and use cases which can be deployed quickly and cost effectively in just a few clicks\n",
    "\n",
    "### Summary  \n",
    "* Compute resources can be considered the brains and processing power required by applications and systems to carry out computational tasks via a series of instructions\n",
    "* AWS Compute is primarily: EC2, ECS, ECR, EKS, Elastic Beanstalk, Lambda, Batch & Lightsail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951f1db-919b-4e1e-a9e6-fab539ce9c0a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "[AWS Cloud Practitioner Exam Guide](https://d1.awsstatic.com/training-and-certification/docs-cloud-practitioner/AWS-Certified-Cloud-Practitioner_Exam-Guide.pdf)\n",
    "\n",
    "## Cloud Concepts (CLF-C01)\n",
    "This course will give an understanding of:\n",
    "* Key cloud concepts such as scalability, elasticity and security\n",
    "* Cloud deployment models such as public, provate and hybrid\n",
    "* Cloud service models including IaaS, PaaS and SaaS\n",
    "\n",
    "### What is Cloud Computing?\n",
    "* **Cloud Computing** - is a remote virtual pool od on-demand shared resources offering Compute, Storage, Database and Network services that can be rapidly deployed at scale\n",
    "* **Virtualization** - allows multiple virtual machines to run on on essentially a seperate operating system and applications while eing physically installed on the same server\n",
    "* **Shared hardware** - a key concept in virtualization and the cloud\n",
    "* **Hypervisor** - a piece of softwareused to create virtualized environments allowing multiple VMs to be installed on the same host. the hypervisor sits between the physical hardware and the virtual machines and creates a shared pool of virtual hardware resources for each of them to access. All VMs see the same hardware. However, they make requests to the hardware via the hypervisor which makes sure that hardware resources get shared between all the VMs as needed and configured.\n",
    "* Benefits of Virtualization\n",
    "    * Reduced capital expenditure (less hardware required)\n",
    "    * Reduced operating costs (less space, power, cooling required as in a traditional data center)\n",
    "    * Smaller footprint (less physical space needed)\n",
    "    * Optimization of resources (cloud vendor and consumer benefit)\n",
    "* Core foundation services of Cloud computing\n",
    "    * Compute - the 'brains' to process your workload. comparable to CPUs and RAM of on-premisis environments\n",
    "    * Storage - allow user to store/save data. comparable to Server hard disks, Network Attached Storage (NAS) and high speed Storage Area Network (SAN)\n",
    "    * Database - allow user to store structured sets of data used by applications. Comparable to SQL server, MySQL etc.\n",
    "    * Network - provide the connectivity to allow compute / storage / database to communicate. Comparable to routers to route traffic between network switches and firewalls to allow/deny traffic to/from an environment\n",
    "    \n",
    "### Cloud Deployment Models  \n",
    "* **Public** - a vender makes available a shared infrastructure of Compute, Storage, Database and Network services which can be provisioned on demand by the public. The user never sees the hardware let alone knows the exact physical location of their data. Hwever, they may specify a region of service which will aid in minimizing data latency. backend and physical maintenance (power, cooling and hardware maintenance) are handled by the vender\n",
    "* **Private** - infrastructure is privately hosted, managed and owned by the entity using it. This gives more direct control to the entity and is ideal for those who wish to keep a tighter grasp of security control. In this case, the hardware is usually held in private. This is different from typical on-premise server farms because cloud principals are applied (virtualization to create a pool of shared compute and network resources). This is more demanding thanthe public cloud approach because of the overhead and maintenance costs which must be assumed by the user.\n",
    "* **Hybrid** - makes use of public and private clouds. is great for handling burst traffic or disaster recovery. a hybrid model is established when a network link is configured between a private cloud and a public cloud. Hybrid clouds are normally short lived: test/dev purposes or transition states from public to private\n",
    "\n",
    "### Key Cloud Concepts\n",
    "* **On-Demand Resourcing** - when you want to provision a resource within the cloud, it's almost immediately available for use\n",
    "* **Scalability** - rabidly scale your environment up/dwn & in/out\n",
    "    * up/down - altering the power and performance of an instance by adding/subtracting compute resources (e.g. CPU or memory)\n",
    "    * in/out - add/remove the number of instances used as compute resources\n",
    "* **Economy of Scale** - Due to the huge scale of resources public cloud offering provide, this offers exceptionally low resource costs to the end user\n",
    "* **Felxibility and Elasticity** - the amount of choice available allows the user to fully customize exactly how the environment should be: amount of resources, how long resources should run and at what scale\n",
    "* **Growth** - cloud computing offers the ability to grow using a wide range of resources and services; much less growth contstraints compared to a classic on-promices environment\n",
    "* **Utility Based Metering** - you oly pay for what you use when you use them.\n",
    "* **Shared Infrastructure** - hosts within the cloud are virtualized; multiple tenants can run on the same hardware. this significantly reduces the amount of physical hardware and supporting resources required. this contributes to the economy od sclae and makes things cheaper for the customer.\n",
    "* **Highly Available** - many services and infrastructure are replicated across different zones and regions. Having data copied to multiple different places automatically ensures the durability and availability of the data and services without needing to specifically set up these redundancies.\n",
    "* **Security** - considered to bemore secure than an onsite data center, because cloud vender have to adher to global compliance programs across many industries and also by applying the shared responsibility model\n",
    "[Shared Responsibility Model](https://cloudacademy.com/blog/aws-shared-responsibility-model-security/)\n",
    "\n",
    "### Cloud Service Models\n",
    "Different levels and manageability and customization over the users use case\n",
    "* **IaaS** - Infrastructure as a Service gives the highest level of customization. Allows the user to be the architect of their own protion of the cloud: configure their own virtual network, configure instances from the OS and up.\n",
    "* **PaaS** - Platform as a Service gives access to a framework that sits on top of the operating system and up. The underlying architecture, host hardware, network components and OS are managed by the vendor. PaaS is great for developers who can focus on designing an app that will sit on top of the PaaS. ex: Heroku\n",
    "* **SaaS** _ Software as a Service (lowest level of service model) allows for the delivery of an application that can be widely accessed and distributed. These are usually very simple in design and appeal to a wider ausience. No requirements to install any software for use. ex: Gmail\n",
    "IaaS>>PaaS>>SaaS\n",
    "\n",
    "### Common use cases of Cloud Computing\n",
    "1. Migration of Production Services: migrate production services from an existing on-premise solution into the cloud\n",
    "2. Traffis Bursting: the public cloud can be used to scale a network and resources up to manage and handle additional traffic during peak use periods.\n",
    "3. Backup / Dissaster Relief: built-in resiliancy ad durability makes the cloud a greater solution for backup requirements than local on-promice solutions. Cloud has nearly unlimited storage space with built in data management lifecycle policies at a very low cost\n",
    "4. Web Hosting - hosting web services on the cloud is advantageous because of the clouds ability to load balance across multiple instances, scale up/down quickly and automatically to reflect changes in traffic.\n",
    "    * CDN: a set of systems which redirect traffic to the closest caching server. CDNs can reduce latency\n",
    "    * DNS services can help manage demand on web servers by redirecting traffice to load balancers for redistribution.\n",
    "5. Test/Dev Environments: public cloud offers users ability to spin up servers on-demand and sht them down when finished. Would would not be financially viable to have these resources around on-premisis\n",
    "6. Prook of Concept: can implement proof of concept desins to help build successful business cases to present to senior management\n",
    "7. Big Data/Data Manipulation: the cloud makes it much easier to manage and manipulate big data. Having an environment to work with big data allows the user to focus on the analysis and processing without the need to worry about the maintenance and underlying architecture.\n",
    "\n",
    "### How Data Center architecture is reflected in the Cloud\n",
    "The data center as a whole and its architecture can be logically broken down as follows:\n",
    "* Location: within each region, Cloud venders may have at least 2 datacenters in different geographic locations for added resiliancy; this is not practical for every individual user to enact\n",
    "* Physical Security: it is the vender's responsibility to ensure it is implementing and achieving the correct certification and governance regarding security\n",
    "* Mechanical & Electrical Infrastructure: Computer Room Air Conditioning (CRAC) includes generators, uninterupted power supplies, AC, fire suppression. In the cloud, it is the vendors responsibility to ensure that they are implementing the correct capacity, resiliancy and testing to ensure their infrastructure\n",
    "* Network Infrastructure (switches, routers, firewalls): networking operates at a software level (no options to instal a physical switch or router). However, you are able to implementcontrols and configurations that simulate these effects (e.g. create a virtual network segmented to different IP addresses allowing the user to deploy resources as required AWS: Virtual Private Clouds, Azure: VNets)\n",
    "* Servers: the Cloud equivalent == instances (VMs). Just as there is a variety of types of servers for on-premisis facilities, there are different types of VMs to suite different needs (e.g. hosting databases vs processing big data)\n",
    "* Storage (NAS, SAN, Block Storage, Backup) is fantastic in the Cloud as it's often regarded as unlimited, hugely scalable annd highly durable. The cloud has a variety of storage types to suite needs. The AWS equivalent of a SAN is Elastic Block Storage (EBS) which offers persistent block level storage and can be detached from one instance and re-attached to another instance.\n",
    "\n",
    "### Is the Cloud right for your business?\n",
    "Where is the business going? What are you trying to achieve? What are the business objectives?\n",
    "* On-Demand Resourcing. for on-site, it can takes weeks or more just to physically get the resources needed to scale up\n",
    "* Scalability. scaling is resource intensive, but using the Cloud eliminates most of the burden and lessens the cost on the user. [Philips Health AWS case study](https://aws.amazon.com/solutions/case-studies/philips-healthsuite-case-study/), [Airbnb case study](https://aws.amazon.com/solutions/case-studies/airbnb-case-study/)\n",
    "* Economies of Scale. get shared wholesale costs on Compute, Storage & Network resources. Savings get passed to end users\n",
    "* Flexibility & Elasticity. can have as many or as few resources as desired without having to guess the capacity up front. Auto-scaled resources with customized thresholds can shrink or expand resources elastically to meet customer demand. [Unilever case study](https://aws.amazon.com/solutions/case-studies/unilever/)\n",
    "* Growth. Cloud rapid deployment allows resources to scale to meet demand.\n",
    "* Utility Based Metering. Only pay fr resources for the time they are used as opposed to running, maintaining equipment 24x7.\n",
    "* Shared Infrastructure. Virtualized environments with multiple tnenats greatly reduces the amount of hardware required.\n",
    "* Highly available. offsite replication is built into storage by design.\n",
    "* Security. Public Cloud security is help to a very high standard and has to meet many global standards, compliance and certifications. Vendors provide security 'of' the cloud while end user provide security 'in' the cloud.\n",
    "\n",
    "### Cloud Business Benefits\n",
    "What else can the Cloud bring me as a business?\n",
    "* Innovation Potential: new and innovative cloud tools are developed all the time. moving to the cloud allows the user to experiment with these approaches in a way that might not be possible for businesses working on top of out-dated data architectures.\n",
    "* Swift go to Market: instant resource availability to push product development reduces time to deploy. [Netflix case study](https://aws.amazon.com/solutions/case-studies/netflix/)\n",
    "* Carbon footprint: shared resources helps reduce carbon emission\n",
    "* Remote Access: opens opportunities for support/management of resources. removes physical constraints on where/how resources are accessed (can outsource to cheap labor (sad face))\n",
    "* Reduce risks: minimize loss or corruption of customer data\n",
    "* Collaboration & Business agility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19932977-d4bb-4a3e-b9c3-41b59ead8291",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## AWS Global Infrastructure: Availability Zones, Regions, Edge Locations, Regional Edge Caches\n",
    "\n",
    "### Availability Zones (AZs) - are the physical data centers of AWS. \n",
    "* multiple data centers located close together can form a single AZ.\n",
    "* each AZ will have at least one other AZ geographically located within the same area (city) that are interconnected with low latency private fiber optic connections and powered by seperate sources. \n",
    "* these links are used to replicate data for resiliency purposes\n",
    "\n",
    "### Regions - localized geographical grouping of multiple AZs which each contain multiple (at least 2) data centers\n",
    "* having global regions allows for compliance with regulations, laws, and governance relating to data storage\n",
    "* regions have a specific 'friendly' and code naming convention\n",
    "* if you  have multiple AWS accounts and you try to coordinate resources within the same AZ (by codename) this may not necessarily mea those resources are physically located within the same AZ\n",
    "\n",
    "### Edge Locations - Edge locations are AWS sites deployed in major cities / high pop density areas across the globe.\n",
    "* are primarily used by end users who are accessing and using your services\n",
    "* ex: if your website hosts instaces inOhio, but a user accesses services from the UK, the user would be redirected to an edge location nearby where cached data could be read and latency reduced\n",
    "\n",
    "### Regional Edge Caches - a new  type of edge location.\n",
    "* has larger cache width than other edge locations. when data is requested at the Edge location that is no longer available, the edge location can retrieve from the regional edge cache instead of the origin server, which would have a higher latency "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c5cd8-dfb0-4846-95d4-216b3c0b2a7c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Compute\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This section covers topics that fall under Technology ('Domain 3') in the official AWS Certified Cloud Practitioner exam blueprint, which accounts for 33% of the exam content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683f4f2-6c89-44dc-a493-8f19ba9d5241",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## AWS Compute Fundamentals\n",
    "\n",
    "### What is Compute in AWS?\n",
    "**Compute** resources can e considered the brains and processing power required by applications and systems to carry out computational tasks via a series of instructions. AWS Cloud compute resources are analogous to common server components such as CPU and RAM.  \n",
    "Within AWS there are a number (and range) of different services and features that offer Compute power:\n",
    "* one extreme: compute services can utilize hundereds of EC2 instances (virttual servers) which may be used continuously for months or even years processing milliions of instructions\n",
    "* other extreme: may only utilize a few hundred milliseconds of compute resource to execute just a few lines of code within AWS Lambda before relinquishing that compute power\n",
    "Indeed, compute resources can be consumed in different quantities, for different lengths of time, across a range of categories, offering a wide scope of performance and benefit optioins\n",
    "\n",
    "[AWS Cloud Compute Index](http://aws.amazon.com/products/compute/) gives a number of different scenarios and suggestions of what Cloud comute resources might be the best fit.\n",
    "\n",
    "### EC2 Elastic Compute Cloud\n",
    "EC2 will likely be the first  and most common compute service used in AWS.  \n",
    "EC2 allows you to deploy virtual servers within your AWS environment.  Most people will require an EC2 instance within their environment as a part of at least one of their solutions.  \n",
    "The EC2 service can be broken down into the following components:\n",
    "* Amazon Machine Images (AMIs) - An AMI is an image baseline with an OS and applications along with custon configurations. AMIs are essentially templates of preconfigured EC2 instances which allow you to quickly launch a new EC2 instance based on the configurstion within the AMI -this means you don't need to install an OS or other supporting software needed for the template use case. When configuing an EC2 instance, selecting an AMI is the first decision choice to make. The AMI catalog lists several different groupungs: Quickstart (45 most common), AWS marketplace (thousands of preconfigured AMIs) & community AMI (ex: Ubuntu configured for model training w/GPUs). Can also make your own AMI from an instance that you configured yourself. This saves you the trouble of manually reloading the same applications to a default Amazon (Linux) AMI. Once made, just launch your custon AMI as the base instance. Very handy for autoscaling.\n",
    "* Instance Types - Once you have selected your AMI, you then select an instance type. Selecting an instance type defines the size of the instance based on a number of parameters (although key params: vCPUs, Memory, Instance Storage, Network Performance):\n",
    "    * Instance Parameters:\n",
    "        * ECU - number of EC2 compute units\n",
    "        * vCPUs - number of virtual CPUs used on the instance\n",
    "        * Physical Processor - processing speed of the instance\n",
    "        * Clock Speed in gigahurtz\n",
    "        * Memory associated with the instance\n",
    "        * Instance storage\n",
    "        * EBS Optimized storage (yes/no)\n",
    "        * Network Performance - rate of data transfer\n",
    "        * IPv6 Support\n",
    "        * Processor architecture\n",
    "        * AES-Ni - encryption instructions (yes/no)\n",
    "        * AVX - supports advanced vector extensions (yes/no)\n",
    "        * Turbo - intel turbo boost?\n",
    "    * Instance Types: different instance types are categorized into different family types that offer distinct performnace benefits.\n",
    "        * Microinstances - minimal cost due to low CPU & mempry power\n",
    "        * General purpose - a balance of compute, storage & memory\n",
    "        * Compute optimized - greater focus on compute for high performance \n",
    "        * FPGA instances - filled  programmable gate arrays for massively parallelized work\n",
    "        * GPU instances - graphics processing applications\n",
    "        * Memory optimized - for large scale in memory applications\n",
    "        * Storage optimized - for applications with specific disk I/O and storage capacity requirements\n",
    "* Instance Purchasing Options\n",
    "    * On-Demand Instances - can be launched at any time for a flat rate. Can run as long/short as needed. Pay by the second & stop paying when the instance stops. These are typically used for short-term applications e.g. testing and development environments.\n",
    "    * Reserved Instances - purchase a set period of time (1 or 3 years) for reduced cost. Best applied to long term, predictable workloads\n",
    "        * All upfront: pay all for the 1 or 3 year arrangement\n",
    "        * Partial upfront: pay partial on a reservation for a smaller discount\n",
    "        * No upfront: get the smallest discount \n",
    "    * Scheduled Instances - pay for reservations on a recurring schedule, either daily, weekly or monthly. You can set up a schedule to run at a set time frame without committing to a 1 or 3 year reservation. However, if you don't use the instance, you will still be charged. \n",
    "    * Spot Instances - Bid for unused EC2 Compute resources. However, there is no guarentee on the period of time. Just need to outbit the AWS spot price which fluctuates with demand. If the AWS price goes above your bit price, you'll get a 2min warning before the enstance is removed from your environment. Bonus: you might score a large EC2 at a very low price, just be sure that you run processes that can be interrupted without harm (batch processes)\n",
    "    * On-Demand Capacity Reservations - reserve capacity based on different attributes such as instance type, platform, tenancy.\n",
    "* Tenancy - relates to the underlying host your EC2 instance will reside on, so essentially the physical server within an AWS Data Center. If you don't need to address any compliance or security issues that require dedicated tenancy, best to go with shared tenancy to reduce overall costs.\n",
    "    * Shared Tenancy - EC2 instance is launched on any available host with the required resources. The same host can be used by multiple customers. AWS security mechanisms prevent one EC2 instance from accessing another on the same host\n",
    "    * Dedicated Instances - Hosted on hardware that no other customer can access. May be required to meet regional/organization compliance. These dedicated instances incurr additional charges\n",
    "    * Dedicated Hosts - Additional visibility abd controol on the physical host. allows to use the same dedicated host to multiple instances.\n",
    "* User Data - allows you to enter commands what will run during the first boot cycle of the instance. Helpful to pull down additional resources and get your environment set up faster. Also get OS updates\n",
    "* Storage Options - selecting storage for your EC2 instance will depend on the instance selected, what you intend to use the instance for and how critical the data is.\n",
    "    * Persistent Storage - available by attaching EBS volumes. EBS volumes are seperated from the EC2 insance and the volumes are attached via AWS network components. Not dissimilar to attaching a flash drive to you computer. Data is automatically duplicated for resiliancy. You can disconnect the colume fro the EC2 instance and still mainttain the data. Can also implement encryptions and take backup storage snapshots\n",
    "    * Ephemeral Storage (temporary) - created by EC2 instances using local storage. Physically attached to the underlying host (similar to a PC's hardrive). Data will remain intact after reboot. However, will NOT persist once the instance is stopped. You cannot detatch ephemeral storage from the instance.\n",
    "* Security - during creation of your EC2 instance you will be asked to select a Security Group for your instance. basically a firewall to protect access (in/out) of the resource. [For more on instance level security](https://cloudacademy.com/blog/aws-security-groups-instance-level-security/)\n",
    "    * at the end of creating your EC2 instance, you will need to create an existing key pair or create a new one. The key pair are Public and Private Keys. The purpose of the keys is to encrypt the login information for Linux and Windows EC2 instances, and tthen decrypt the same information allowing you to authenticate onto the instance.\n",
    "    * The Pubic key is held and kept by AWS, the Private key is the user's responsibility to keep and ensure that it is not lost. It is possible to use the same key pair for different instances. \n",
    "    * It is the user's responsibility to maintain and install the latest OS and security patches released by the OS vendor as dictated witthin the AWS shared responsibility model.\n",
    "* Status Checks - help monitor the AWS systems requirements used to keep the instance running\n",
    "    * System Status Checks - issue with the underlying host (network, power issues, out of our control & up to AWS. best recourse: restart)\n",
    "    * Instance Status Checks - issue with the configuration of the EC2 instance (kernel, memory, configuration corrupt data etc. requires more troubleshooting)\n",
    "\n",
    "### ECS Elastic Container Service\n",
    "\n",
    "\n",
    "### ECR Elastic Container Registry\n",
    "\n",
    "\n",
    "### EKS Elastic Container Service for Kubernetes\n",
    "\n",
    "\n",
    "### AWS Elastic Beanstalk\n",
    "\n",
    "\n",
    "### AWS Lambda\n",
    "\n",
    "\n",
    "### AWS Batch\n",
    "\n",
    "\n",
    "### Amazon Lightsail\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611da95-d6e3-4b39-89ea-74ec815c99ef",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Elastic Load Balancing\n",
    "\n",
    "\n",
    "### What is an Elastic Load Balancer?\n",
    "\n",
    "\n",
    "### SSL Server Certificates\n",
    "\n",
    "\n",
    "### Application Load Balancers\n",
    "\n",
    "\n",
    "### Network Load Balancers\n",
    "\n",
    "\n",
    "### Classic Load Balancers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e019059a-fed8-41bf-9a72-248c9025c6a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<br>\n",
    "\n",
    "## EC2 Auto Scaling\n",
    "\n",
    "\n",
    "### EC2 Auto Scaling\n",
    "\n",
    "\n",
    "### Components of EC2 Auto Scaling\n",
    "\n",
    "\n",
    "### Using ELB and Auto Scaling Together\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de88ade-20fc-4f38-89a3-952e8c58a018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
