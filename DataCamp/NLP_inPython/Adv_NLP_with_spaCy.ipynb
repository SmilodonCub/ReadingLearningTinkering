{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Advanced NLP with `spaCy`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding words, phrases, names and concepts\n",
    "\n",
    "### Intro to `spaCy`\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the English language class\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# create an nlp object\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "the nlp object contains a processing pipeline, language-specific rules for tokenization\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "world\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# a Doc object is created by processing a string of text with the nlp object\n",
    "doc = nlp( \"Hello world!\" )\n",
    "\n",
    "#iterate over tokens in a doc:\n",
    "for token in doc:\n",
    "    print( token.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world\n",
      "world\n"
     ]
    }
   ],
   "source": [
    "# index into the Doc to get a single token\n",
    "token =  doc[1]\n",
    "print( token )\n",
    "\n",
    "# get the token text by way of the .text attribute\n",
    "print( token.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "world!\n"
     ]
    }
   ],
   "source": [
    "# Span object: consistes of multiple tokens .. a slice of the Doc object\n",
    "span = doc[1:4]\n",
    "print( span.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:   [0, 1, 2, 3, 4]\n",
      "Text:   ['It', 'costs', '$', '5', '.']\n",
      "is_alpha   [True, True, False, False, False]\n",
      "is_punct   [False, False, False, False, True]\n",
      "like_num   [False, False, False, True, False]\n"
     ]
    }
   ],
   "source": [
    "# lexical attributes\n",
    "doc = nlp( \"It costs $5.\" )\n",
    "\n",
    "print( 'Index:  ', [ token.i for token in doc ] )\n",
    "print( 'Text:  ', [ token.text for token in doc ] )\n",
    "print( 'is_alpha  ', [ token.is_alpha for token in doc ] )\n",
    "print( 'is_punct  ', [ token.is_punct for token in doc ] )\n",
    "print( 'like_num  ', [ token.like_num for token in doc ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liebe Grüße!\n"
     ]
    }
   ],
   "source": [
    "# Import the German language class\n",
    "from spacy.lang.de import German\n",
    "\n",
    "# Create the nlp object\n",
    "nlp = German()\n",
    "\n",
    "# Process a text (this is German for: \"Kind regards!\")\n",
    "doc = nlp(\"Liebe Grüße!\")\n",
    "\n",
    "# Print the document text\n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage found: 60\n",
      "Percentage found: 4\n"
     ]
    }
   ],
   "source": [
    "# Process the text\n",
    "doc = nlp(\"In 1990, more than 60% of people in East Asia were in extreme poverty. Now less than 4% are.\")\n",
    "\n",
    "# Iterate over the tokens in the doc\n",
    "for token in doc:\n",
    "    # Check if the token resembles a number\n",
    "    if token.like_num:\n",
    "        # Get the next token in the document\n",
    "        next_token = doc[token.i+1]\n",
    "        # Check if the next token's text equals '%'\n",
    "        if next_token.text == '%':\n",
    "            print('Percentage found:', token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Statistical Models\n",
    "\n",
    "enable `spaCy` to predict linguistic attributes in context  \n",
    "\n",
    "* POS tags\n",
    "* suntactic dependencies\n",
    "* named entities\n",
    "\n",
    "train on labeled example texts and can be updated with more examples to fine-tune predictions  \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "She PRON nsubj ate\n",
      "ate VERB ROOT ate\n",
      "the DET det pizza\n",
      "pizza NOUN dobj ate\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# load the small english model\n",
    "nlp = spacy.load( 'en_core_web_sm' )\n",
    "#process the text\n",
    "doc = nlp( 'She ate the pizza' )\n",
    "#iterate over the tokens\n",
    "for token in doc:\n",
    "    print( token.text, token.pos_, token.dep_, token.head.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "U.K. GPE\n",
      "$1 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp( u\"Apple is looking at buying U.K. startup for $1 billion\" )\n",
    "for ent in doc.ents: \n",
    "    print( ent.text, ent.label_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries, cities, states\n",
      "noun, proper singular\n",
      "direct object\n"
     ]
    }
   ],
   "source": [
    "# for some help\n",
    "print( spacy.explain( 'GPE' ) )\n",
    "print( spacy.explain( 'NNP' ) )\n",
    "print( spacy.explain( 'dobj' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It          PRON      dep       \n",
      "’s          INTJ      intj      \n",
      "official    ADJ       amod      \n",
      ":           PUNCT     punct     \n",
      "Apple       PROPN     nsubj     \n",
      "is          AUX       ROOT      \n",
      "the         DET       det       \n",
      "first       ADJ       amod      \n",
      "U.S.        PROPN     nmod      \n",
      "public      ADJ       amod      \n",
      "company     NOUN      attr      \n",
      "to          PART      aux       \n",
      "reach       VERB      relcl     \n",
      "a           DET       det       \n",
      "$           SYM       quantmod  \n",
      "1           NUM       compound  \n",
      "trillion    NUM       nummod    \n",
      "market      NOUN      compound  \n",
      "value       NOUN      dobj      \n"
     ]
    }
   ],
   "source": [
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp( text)\n",
    "\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print('{:<12}{:<10}{:<10}'.format(token_text, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "first ORDINAL\n",
      "U.S. GPE\n",
      "$1 trillion MONEY\n"
     ]
    }
   ],
   "source": [
    "text = \"It’s official: Apple is the first U.S. public company to reach a $1 trillion market value\"\n",
    "\n",
    "# Process the text\n",
    "doc = nlp( text )\n",
    "\n",
    "# Iterate over the predicted entities\n",
    "for ent in doc.ents:\n",
    "    # print the entity text and its label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Rule-based Matching\n",
    "\n",
    "**match patterns** - list of dictionaries, one per token\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9528407286733565721, 1, 3)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load( 'en_core_web_sm' )\n",
    "matcher = Matcher( nlp.vocab)\n",
    "#add pattern to the matcher\n",
    "pattern = [ { 'ORTH':'iPhone' }, { 'ORTH':'X' } ]\n",
    "matcher.add( 'IPHONE_PATTERN', [ pattern ] )\n",
    "#return matches on a doc\n",
    "doc = nlp( 'New iPhone X release date leaked' )\n",
    "matches = matcher( doc )\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone X\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in matches:\n",
    "    # iterate over and matches and create a span object\n",
    "    matched_span = doc[ start:end ]\n",
    "    print( matched_span.text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(17311505950452258848, 0, 5)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lexical matches\n",
    "pattern = [\n",
    "    { 'IS_DIGIT': True },\n",
    "    { 'LOWER':'fifa' },\n",
    "    { 'LOWER':'world' },\n",
    "    { 'LOWER':'cup' },\n",
    "    { 'IS_PUNCT': True }\n",
    "]\n",
    "\n",
    "doc = nlp( '2018 FIFA World Cup: France won!')\n",
    "matcher.add( 'FIFA_PATTERN', [pattern] )\n",
    "matches = matcher( doc )\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18437031736592595799, 1, 3), (18437031736592595799, 6, 8)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = [\n",
    "    { 'LEMMA': 'love', 'POS': 'VERB' },\n",
    "    { 'POS': 'NOUN' }\n",
    "]\n",
    "\n",
    "doc = nlp( 'I loved dogs but now I love cats more' )\n",
    "matcher.add( 'LOVE', [pattern] )\n",
    "matches = matcher( doc )\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Using operators and quantifiers\n",
    "\n",
    "| Operator |    Description   |\n",
    "|:-----------:|:----------------------------:|\n",
    "| {'OP': '!'} |    Negation: match 0 times   |\n",
    "| {'OP': '?'} | Optional: match 0 or 1 times |\n",
    "| {'OP': '+'} | Match 1 or more times        |\n",
    "| {'OP': '*'} | Match 0 or more times        |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: iOS 7\n",
      "Match found: iOS 11\n",
      "Match found: iOS 10\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"After making the iOS update you won't notice a radical system-wide redesign: nothing like the aesthetic upheaval we got with iOS 7. Most of iOS 11's furniture remains the same as in iOS 10. But you will discover some tweaks once you delve a little deeper.\")\n",
    "\n",
    "# Write a pattern for full iOS versions (\"iOS 7\", \"iOS 11\", \"iOS 10\")\n",
    "pattern = [{'TEXT': 'iOS'}, {'IS_DIGIT': True}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('IOS_VERSION_PATTERN', [pattern])\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total matches found: 3\n",
      "Match found: downloaded Fortnite\n",
      "Match found: downloading Minecraft\n",
      "Match found: download Winzip\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"i downloaded Fortnite on my laptop and can't open the game at all. Help? so when I was downloading Minecraft, I got the Windows version where it is the '.zip' folder and I used the default program to unpack it... do I also need to download Winzip?\")\n",
    "\n",
    "# Write a pattern that matches a form of \"download\" plus proper noun\n",
    "pattern = [{'LEMMA': 'download'}, {'POS': 'PROPN'}]\n",
    "\n",
    "# Add the pattern to the matcher and apply the matcher to the doc\n",
    "matcher.add('DOWNLOAD_THINGS_PATTERN', [pattern] )\n",
    "matches = matcher(doc)\n",
    "print('Total matches found:', len(matches))\n",
    "\n",
    "# Iterate over the matches and print the span text\n",
    "for match_id, start, end in matches:\n",
    "    print('Match found:', doc[start:end].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
