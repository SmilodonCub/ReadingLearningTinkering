{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation in `Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Source Language) $\\longrightarrow$ (Target Language)  \n",
    "\n",
    "One-hot encoded vectors:  \n",
    "\n",
    "* a sparse vector of ones and zeros\n",
    "    * 1: token is present\n",
    "    * 0: token is not present\n",
    "* vector length is determines by the size of the vocabulary\n",
    "    * vocabulary = set of tokens in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# mapping that contaains words and their corresponding indices\n",
    "word2index = { 'I':0, 'like':1, 'cats':2 }\n",
    "# converting words to IDs or indices\n",
    "words = [ 'I', 'like', 'cats' ]\n",
    "word_ids = [ word2index[w] for w in words ]\n",
    "print( word_ids )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', [1.0, 0.0, 0.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0, 0.0, 0.0]), ('cats', [0.0, 0.0, 1.0, 0.0, 0.0])]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding with keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "onehot_1 = to_categorical( word_ids, num_classes=5 )\n",
    "print( [ (w,ohe.tolist()) for w,ohe in zip( words, onehot_1 )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# exploring the `to_categorical()` function\n",
    "def compute_onehot_length(words, word2index):\n",
    "  # Create word IDs for words\n",
    "  word_ids = [word2index[w] for w in words]\n",
    "  # Convert word IDs to onehot vectors\n",
    "  onehot = to_categorical(word_ids)\n",
    "  # Return the length of a single one-hot vector\n",
    "  return onehot.shape[1]\n",
    "\n",
    "word2index = {\"He\":0, \"drank\": 1, \"milk\": 2}\n",
    "# Compute and print onehot length of a list of words\n",
    "print(compute_onehot_length(['He','drank','milk'], word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length_1 => 9  and length_2 =>  6\n"
     ]
    }
   ],
   "source": [
    "# use the num_classes parameter to set the length of the vectors\n",
    "word2index = {'He': 6,'I': 0,'We': 3,'cats': 2,'dogs': 5,'hates': 7,'like': 4,'rabbits': 8}\n",
    "words_1 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"He\", \"hates\", \"rabbits\"]\n",
    "# Call compute_onehot_length on words_1\n",
    "length_1 = compute_onehot_length(words_1, word2index)\n",
    "\n",
    "words_2 = [\"I\", \"like\", \"cats\", \"We\", \"like\", \"dogs\", \"We\", \"like\", \"cats\"]\n",
    "# Call compute_onehot_length on words_2\n",
    "length_2 = compute_onehot_length(words_2, word2index)\n",
    "\n",
    "# Print length_1 and length_2\n",
    "print(\"length_1 =>\", length_1, \" and length_2 => \", length_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Encoder Decoder Model\n",
    "\n",
    "A machine translation model works by, first, consuming words of the source language sequentially, and then, sequentially predicting the corresponding words in the target language  \n",
    "\n",
    "Input $\\longrightarrow$ **Encoder Model** $\\longrightarrow$ Context Vector $\\longrightarrow$  **Decoder Model** $\\longrightarrow$ Output\n",
    "\n",
    "**Writing the Encoder**  \n",
    "\n",
    "    def words2onehot( word_list, word2index ):\n",
    "        word_ids = [word2index[w] for w in word_list]\n",
    "        onehot = to_categorical( word_ids, 3 )\n",
    "        return onehot\n",
    "        \n",
    "    def encoder( onehot ):\n",
    "        word_ids = np.argmax( onehot, axis=1 ):\n",
    "        return word_ids \n",
    "        \n",
    "    onehot = word2onehot([\"I', 'like', 'cats']), words2index )\n",
    "    context = encoder( onehot )\n",
    "    print( context )\n",
    "    \n",
    "**Writing the Decoder**  \n",
    "\n",
    "    def decoder( context_vector ):\n",
    "        word_ids_rev = context_vector[::-1]\n",
    "        onehot_rev = to_categorical( word_ids_rev, 3 )\n",
    "        return onehot_rev\n",
    "        \n",
    "    def onehot2words( onehot, index2words):\n",
    "        ids = np.argmax( onehot, axis = 1 )\n",
    "        return [indext2word[id] for id in ids]\n",
    "        \n",
    "    onehot_rev = decoder( context )\n",
    "    reversed_words = onehot2words( onehot_rev, index2word )\n",
    "    print( reversed_words )\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', [1.0, 0.0, 0.0]), ('like', [0.0, 1.0, 0.0]), ('cats', [0.0, 0.0, 1.0])]\n"
     ]
    }
   ],
   "source": [
    "# The encoder\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "word2index = {'I': 0, 'cats': 2, 'like': 1}\n",
    "\n",
    "def words2onehot(word_list, word2index):\n",
    "  # Convert words to word IDs\n",
    "  word_ids = [word2index[w] for w in word_list]\n",
    "  # Convert word IDs to onehot vectors and return the onehot array\n",
    "  onehot = to_categorical(word_ids, num_classes=3)\n",
    "  return onehot\n",
    "\n",
    "words = [\"I\", \"like\", \"cats\"]\n",
    "# Convert words to onehot vectors using words2onehot\n",
    "onehot = words2onehot(words, word2index)\n",
    "# Print the result as (<word>, <onehot>) tuples\n",
    "print([(w,ohe.tolist()) for w,ohe in zip(words, onehot)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "# Encoder: Text reversing model\n",
    "def encoder(onehot):\n",
    "  # Get word IDs from onehot vectors and return the IDs\n",
    "  word_ids = np.argmax(onehot, axis=1)\n",
    "  return word_ids\n",
    "\n",
    "# Define \"We like dogs\" as words\n",
    "words = ['We','like','dogs']\n",
    "# Define the word2index dict\n",
    "word2index = {'We': 0, 'dogs': 2, 'like': 1}\n",
    "\n",
    "# Convert words to onehot vectors using words2onehot\n",
    "onehot = words2onehot(words, word2index)\n",
    "# Get the context vector by using the encoder function\n",
    "context = encoder(onehot)\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the Decoder\n",
    "# Define the onehot2words function that returns words for a set of onehot vectors\n",
    "def onehot2words(onehot, index2word):\n",
    "  ids = np.argmax(onehot, axis=1)\n",
    "  res = [index2word[id] for id in ids]\n",
    "  return res\n",
    "# Define the decoder function that returns reversed onehot vectors\n",
    "def decoder(context_vector):\n",
    "  word_ids_rev = context_vector[::-1]\n",
    "  onehot_rev = to_categorical(word_ids_rev, num_classes=3)\n",
    "  return onehot_rev\n",
    "# Convert context to reversed onehot vectors using decoder\n",
    "onehot_rev = decoder(context)\n",
    "# Get the reversed words using the onehot2words function\n",
    "reversed_words = onehot2words(onehot_rev, index2word)\n",
    "print(reversed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Understanding Sequential Models\n",
    "\n",
    "**Time Series inputs and Sequential Models**  \n",
    "\n",
    "* sentences as time series input\n",
    "    * current word is affected by the previous words\n",
    "* The encoder/decoder uses a machine leaarning model that: \n",
    "    * **sequential model** - can learn from times series inputs \n",
    "    \n",
    "**Gated Recurrent Unit (GRU)** - sequential GRU units take in input ad pass a hidden state to the next unit until the sequence is processes. the hidden states at each unit represent the 'memory' of what the model has seen.  \n",
    "\n",
    "**`Keras` (functional API) refresher**  \n",
    "\n",
    "* `Keras` has two important objects: `Layer` and `Model` objects\n",
    "* Input Layer\n",
    "    * `inp = keras.layers.Input( shape = (...))`\n",
    "* Hidden Layer\n",
    "    * `layer = keras.layers.GRU(...)`\n",
    "* Output\n",
    "    * `out = layer( inp )`\n",
    "* Model\n",
    "    * `mode = Model( inputs=inp, outputs=out )`\n",
    "    \n",
    "**Understanding the Shape of the Data**  \n",
    "* Sequence data is 3-dimensional\n",
    "    1. **batch dimension** - the number of sequences\n",
    "    2. **time dimension** - the length of the sequences\n",
    "    3. **Input dimention** - length of the onehot vector (vocab length)\n",
    "    \n",
    "** Implementing GRUs with `Keras`**  \n",
    "\n",
    "Defining `Keras` layers:  \n",
    "\n",
    "    inp = keras.layers.Input( batchdim, timedim, inputdim ) \n",
    "    #for a model that takes arbitrary number of samples, leave out batchdim\n",
    "    gru_out, gru_state = keras.layers.GRU( 10, return_state =True )(inp)\n",
    "    #alternatively:\n",
    "    gru_out = keras.layers.GRU( 10, return_sequences=True )(inp)\n",
    "    \n",
    "Defining a `Keras` model:  \n",
    "\n",
    "    model = keras.model.Model( input=inp, outputs-gru_out )\n",
    "\n",
    "Predicting with the `Keras` model:  \n",
    "\n",
    "    x = np.random.normal( size = ( batchdim, timedim, inputdim ) )\n",
    "    y = model.predict( x )\n",
    "    print( \"shape (y) =', y.shape, \"\\ny =\\n\", y )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (y) = (2, 10) \n",
      "y = \n",
      " [[-0.54010355  0.3191152   0.03250751  0.16956952  0.2524814   0.0261744\n",
      "   0.0873507  -0.18221648  0.40233934  0.38475484]\n",
      " [-0.47358763  0.4035396   0.04614807  0.29768118  0.3857712   0.06155618\n",
      "   0.21121213 -0.32127964  0.34948695  0.2716644 ]]\n"
     ]
    }
   ],
   "source": [
    "#implement a simple model that has an input layer and a GRU layer. \n",
    "#You will then use the model to produce output values for a random input array.\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "# Define an input layer\n",
    "inp = keras.layers.Input(batch_shape=(2,3,4))\n",
    "# Define a GRU layer that takes in the input\n",
    "gru_out = keras.layers.GRU(10)(inp)\n",
    "\n",
    "# Define a model that outputs the GRU output\n",
    "model = keras.models.Model(inputs=inp, outputs=gru_out)\n",
    "\n",
    "x = np.random.normal(size=(2,3,4))\n",
    "# Get the output of the model and print the result\n",
    "y = model.predict(x)\n",
    "print(\"shape (y) =\", y.shape, \"\\ny = \\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (y1) =  (2, 10)  shape (y2) =  (5, 10)\n"
     ]
    }
   ],
   "source": [
    "#see how you can use Keras models to accept arbitrary sized batches of inputs\n",
    "\n",
    "# Define an input layer\n",
    "inp = keras.layers.Input(shape=(3,4))\n",
    "# Define a GRU layer that takes in the input\n",
    "gru_out = keras.layers.GRU(10)(inp)\n",
    "# Define a model that outputs the GRU output\n",
    "model = keras.models.Model(inputs=inp, outputs=gru_out)\n",
    "\n",
    "x1 = np.random.normal(size=(2,3,4))\n",
    "x2 = np.random.normal(size=(5,3,4))\n",
    "\n",
    "# Get the output of the model and print the result\n",
    "y1 = model.predict(x1)\n",
    "y2 = model.predict(x2)\n",
    "print(\"shape (y1) = \", y1.shape, \" shape (y2) = \", y2.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define the Input layer\n",
    "inp = keras.layers.Input(batch_shape=(3,20,5))\n",
    "# Define a GRU layer that takes in inp as the input\n",
    "gru_out1 = keras.layers.GRU(10)(inp)\n",
    "print(\"gru_out1.shape = \", gru_out1.shape)\n",
    "\n",
    "# Define the second GRU and print the shape of the outputs\n",
    "gru_out2, gru_state = keras.layers.GRU(10, return_state=True)(inp)\n",
    "print(\"gru_out2.shape = \", gru_out2.shape)\n",
    "print(\"gru_state.shape = \", gru_state.shape)\n",
    "\n",
    "# Define the third GRU layer which will return all the outputs\n",
    "gru_out3 = keras.layers.GRU(10, return_sequences=True)(inp)\n",
    "print(\"gru_out3.shape = \", gru_out3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Implementing the Encoder/Decoder Model with `Keras`\n",
    "\n",
    "### Implementing the Encoder\n",
    "\n",
    "Understanding the Data:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( 'vocab_fr.txt' ) as f:\n",
    "    fr_text = f.readlines()\n",
    "    \n",
    "with open( 'vocab_en.txt' ) as f:\n",
    "    en_text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENglish:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "\n",
      "Frnedch:  new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "\n",
      "ENglish:  the united states is usually chilly during july , and it is usually freezing in november .\n",
      "\n",
      "Frnedch:  les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "\n",
      "ENglish:  california is usually quiet during march , and it is usually hot in june .\n",
      "\n",
      "Frnedch:  california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for en_sent, fr_sent in zip( en_text[:3], fr_text[:3]):\n",
    "    print( 'ENglish: ', en_sent )\n",
    "    print( 'Frnedch: ', fr_sent )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Tokenizing the Sentences\n",
    "\n",
    "Now to look at some of the attriutes of the DataSet  \n",
    "**Tokenization** - the process of breaking a sentence/phrase to individual tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first sentence:  new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "\n",
      "\tWords:  ['new', 'jersey', 'is', 'sometimes', 'quiet', 'during', 'autumn', ',', 'and', 'it', 'is', 'snowy', 'in', 'april', '.\\n']\n"
     ]
    }
   ],
   "source": [
    "first_sent = en_text[0]\n",
    "print( 'first sentence: ', first_sent )\n",
    "first_words = first_sent.split(' ')\n",
    "print( '\\tWords: ', first_words )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Computing the average length of sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLIGH mean sentence length =  13.225678224285508\n",
      "FRENCH mean sentence length =  14.226737269693892\n"
     ]
    }
   ],
   "source": [
    "sent_length = [len(text.split(' ')) for text in en_text]\n",
    "mean_en_length = np.mean( sent_length )\n",
    "print( 'ENGLIGH mean sentence length = ', mean_en_length)\n",
    "\n",
    "sent_length = [len(text.split(' ')) for text in fr_text]\n",
    "mean_fr_length = np.mean( sent_length )\n",
    "print( 'FRENCH mean sentence length = ', mean_fr_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENGLISH vocab size =  228\n",
      "FRENCH vocab size =  357\n"
     ]
    }
   ],
   "source": [
    "all_words = []\n",
    "[all_words.extend( sent.split(' ')) for sent in en_text]\n",
    "en_vocab_size = len( set( all_words ) )\n",
    "print( 'ENGLISH vocab size = ', en_vocab_size )\n",
    "\n",
    "all_words = []\n",
    "[all_words.extend( sent.split(' ')) for sent in fr_text]\n",
    "fr_vocab_size = len( set( all_words ) )\n",
    "print( 'FRENCH vocab size = ', fr_vocab_size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "**Implementing the Encoder with `Keras`  \n",
    "\n",
    "Input Layer:  \n",
    "\n",
    "    en_inputs = Input( shape=(en_len, en_vocab))\n",
    "    \n",
    "GRU Layer:  \n",
    "\n",
    "    en_gru = GRU( hsize, return_state=True )\n",
    "    en_out, en_state = en_gru( en_Inputs )\n",
    "    \n",
    "`Keras` Model:  \n",
    "\n",
    "    encoder = Model( inputs=en_inputs, outputs=en_state )\n",
    "    print( encoder.summary() )\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 15, 150)]         0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  [(None, 48), (None, 48)]  28800     \n",
      "=================================================================\n",
      "Total params: 28,800\n",
      "Trainable params: 28,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# defining the Encoder\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "en_len = 15\n",
    "en_vocab = 150\n",
    "hsize = 48\n",
    "\n",
    "# Define an input layer\n",
    "en_inputs = keras.layers.Input(shape=(en_len, en_vocab))\n",
    "# Define a GRU layer which returns the state\n",
    "en_gru = keras.layers.GRU(hsize, return_state = True)\n",
    "# Get the output and state from the GRU\n",
    "en_out, en_state = en_gru(en_inputs)\n",
    "# Define and print the model summary\n",
    "encoder = keras.models.Model(inputs=en_inputs, outputs=en_state)\n",
    "print(encoder.summary() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Implementing the Decoder\n",
    "\n",
    "**Encoder-Decoder Model**  \n",
    "\n",
    "* Encoder consumes the English words one-by-one\n",
    "* Finally produces the context vector\n",
    "* Decoder takes the context vector as the initial state\n",
    "* Decoder produces French words one-by-one\n",
    "* Decoder is implemented using a `Keras` GPU layer. GRU requires two inputs:\n",
    "    1. a time series input\n",
    "    2. a hidden state\n",
    "\n",
    "How to produce the time series input for the GRU layer?  \n",
    "\n",
    "1. repeat the context vetor from the encoder N-many times\n",
    "    * ex: To produce a french sentence of 10 words, you repeat the context vector 10 times. \n",
    "    \n",
    "Understanding the `RepeatVector` layer:  \n",
    "\n",
    "* takes one argument which defines the sequence length of the required output\n",
    "* takes in an input of (batch_size, input_size)\n",
    "* output data will have the shape ( batch_size, sequence_length, input_size )\n",
    "\n",
    "**Defining a `RepeatVector` layer**  \n",
    "\n",
    "    from tensorflow.keras.layers import RepeatVector\n",
    "    rep = RepeatVector( 5 )\n",
    "    \n",
    "    r_inp = Input( shape( 3, ) )\n",
    "    r_out = rep( r_inp )\n",
    "    \n",
    "    repeat_model = Model( inputs= r_inp, outputs = r_out )\n",
    "    \n",
    "**Predicting with the Model**  \n",
    "\n",
    "    x = np.array( [ [0,1,2], [3,4,5] ] )\n",
    "    y = repeat_model.predict( x )\n",
    "    print( 'x.shape = ', x.shape, '\\ny.shape = ', y.shape )\n",
    "\n",
    "**Implementing the Decoder**  \n",
    "\n",
    "    de_inputs = RepeatVector( fr_len )( en_state )\n",
    "    decoder_gru = GRU( hsize, return_sequences=True )\n",
    "    gru_outputs = decoder_gru( de_inputs, initial_state=en_state )\n",
    "\n",
    "**Defining the Model**  \n",
    "\n",
    "    enc_dec = Model( inputs= en_inputs, outputs = gru_outputs )\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =  (2, 2) \n",
      "y.shape =  (2, 6, 2)\n"
     ]
    }
   ],
   "source": [
    "# explore how the RepeatVector layer works\n",
    "from tensorflow.keras.layers import Input, RepeatVector\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "inp = Input(shape=(2,))\n",
    "# Define a RepeatVector that repeats the input 6 times\n",
    "rep = RepeatVector(6)(inp)\n",
    "# Define a model\n",
    "model = Model(inputs=inp, outputs=rep)\n",
    "# Define input x\n",
    "x = np.array([[0,1], [2,3]])\n",
    "# Get model prediction y\n",
    "y = model.predict( x )\n",
    "print('x.shape = ',x.shape,'\\ny.shape = ',y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 15, 150)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     [(None, 48), (None,  28800       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 20, 48)       0           gru_5[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_6 (GRU)                     (None, 20, 48)       14112       repeat_vector_2[0][0]            \n",
      "                                                                 gru_5[0][1]                      \n",
      "==================================================================================================\n",
      "Total params: 42,912\n",
      "Trainable params: 42,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# implement the decoder and define an end-to-end model going from encoder inputs to the decoder GRU outputs. \n",
    "\n",
    "hsize = 48\n",
    "fr_len = 20\n",
    "# Define a RepeatVector layer\n",
    "de_inputs = RepeatVector(fr_len)(en_state)\n",
    "# Define a GRU model that returns all outputs\n",
    "decoder_gru = keras.layers.GRU(hsize, return_sequences=True)\n",
    "# Get the outputs of the decoder\n",
    "gru_outputs = decoder_gru(de_inputs, initial_state=en_state)\n",
    "# Define a model with the correct inputs and outputs\n",
    "enc_dec = Model(inputs=en_inputs, outputs=gru_outputs)\n",
    "enc_dec.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Dense and TimeDistributed Layers \n",
    "\n",
    "Introduction to the **Dense Layer** - a dense layer can be used to implement a fully-connected layer of a neural network.  \n",
    "\n",
    "* Dense Layer takes an input vector and converts to a probabilistic prediction\n",
    "    * y = Weightd.x + Bias  \n",
    "    \n",
    "Defining  Dense Laye with `Keras`:\n",
    "\n",
    "    dense = keras.layers.Dense( vicab_size, activation = 'softmax' )\n",
    "    inp = Input( shape=( vocab_size, )\n",
    "    pred = dense( inp )\n",
    "    model = Model( inputs=inp, outputs=pred )\n",
    "    \n",
    "Defining a Dense layer with custom initialization:\n",
    "\n",
    "    from tensorflow.keras.initializers import RandomNormal\n",
    "    init = RandomNormal( mean = 0.0, stddev = 0.05, seed = 6000 )\n",
    "    dense = Dense( vocab_size, activation='softmax', kernel_initializer=init, bias_initializer=init )\n",
    "    \n",
    "Inputs and outputs of a Dense Layer:  \n",
    "\n",
    "* Dense softmax layer\n",
    "    * takes a (batch_size, input_size) array\n",
    "    * produces a ( batch_size, num_classes ) array\n",
    "    * output for each sample is a probability distribution over the classes which sums to 1\n",
    "    * you can get the class of each sample using `np.argmax(y, axis=-1)`\n",
    "    \n",
    "Use a `TimeDistributed` layer as a wrapper for a `Dense` layer  \n",
    "\n",
    "    dense_time = TimeDistributedd( Dense( vocab_size, activation='softmax' ) )\n",
    "    inp = Input( shape = (  ) )\n",
    "    pred = dense_time( inp )\n",
    "    model = Model( inputs=inp, outputs=pred )\n",
    "    \n",
    "`TimeDistributed` Layer takes (batch_size, sequence_len, input_size) $\\longrightarrow$ ( batch_size, sequence_len, num_classes ) array  \n",
    "\n",
    "can get the class of each sample using `np.argmax( y, axis=-1 )`\n",
    "\n",
    "Iterating through time-distributed data:\n",
    "\n",
    "    for t in range( sequence_len ):\n",
    "        for prob, c in zip( y[:,t,:], classes[:,t]):\n",
    "            print( \"prob: ', prob, \", Class: ', c )\n",
    "            \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd1b2d83b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Mark has probabilities [0.3929537  0.37995604 0.22709025] and wins Gift voucher\n",
      "John has probabilities [0.33233336 0.34169823 0.32596847] and wins Car\n",
      "Kelly has probabilities [0.35587627 0.35802534 0.28609842] and wins Car\n"
     ]
    }
   ],
   "source": [
    "init = keras.initializers.RandomNormal( mean = 0.0, stddev = 0.05, seed = 6000 )\n",
    "# Define an input layer with batch size 3 and input size 3\n",
    "inp = Input(batch_shape = (3,3))\n",
    "# Get the output of the 3 node Dense layer\n",
    "pred = keras.layers.Dense(3, activation='softmax', kernel_initializer=init, bias_initializer=init)(inp)\n",
    "model = Model(inputs=inp, outputs=pred)\n",
    "\n",
    "names = [\"Mark\", \"John\", \"Kelly\"]\n",
    "prizes = [\"Gift voucher\", \"Car\", \"Nothing\"]\n",
    "x = np.array([[5, 0, 1], [0, 3, 1], [2, 2, 1]])\n",
    "# Compute the model prediction for x\n",
    "y = model.predict(x)\n",
    "# Get the most probable class for each sample\n",
    "classes = np.argmax(y, axis=-1)\n",
    "print(\"\\n\".join([\"{} has probabilities {} and wins {}\".format(n,p,prizes[c]) \\\n",
    "                 for n,p,c in zip(names, y, classes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names=\n",
      " [['Mark', 'John', 'Kelly'], ['Jenny', 'Shan', 'Sarah']] \n",
      "x=\n",
      " [[[5 0 1]\n",
      "  [1 1 0]]\n",
      "\n",
      " [[0 3 1]\n",
      "  [0 4 0]]\n",
      "\n",
      " [[2 2 1]\n",
      "  [6 0 1]]] \n",
      "x.shape= (3, 2, 3)\n",
      "WARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd1e4586170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Game 1: Mark has probs [0.3929537  0.37995604 0.22709025] and wins Gift voucher\n",
      "\n",
      "Game 1: John has probs [0.33233336 0.34169823 0.32596847] and wins Car\n",
      "\n",
      "Game 1: Kelly has probs [0.35587627 0.35802534 0.28609842] and wins Car\n",
      "\n",
      "Game 2: Jenny has probs [0.34050465 0.3426381  0.31685725] and wins Car\n",
      "\n",
      "Game 2: Shan has probs [0.3069249  0.32335538 0.36971974] and wins Nothing\n",
      "\n",
      "Game 2: Sarah has probs [0.3994818  0.38477215 0.21574609] and wins Gift voucher\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = [['Mark', 'John', 'Kelly'], ['Jenny', 'Shan', 'Sarah']]\n",
    "x = np.array([[[5, 0, 1],[1, 1, 0]],\n",
    "           [[0, 3, 1],[0, 4, 0]],\n",
    "           [[2, 2, 1],[6, 0, 1]]])\n",
    "# Print names and x\n",
    "print('names=\\n',names, '\\nx=\\n',x, '\\nx.shape=', x.shape)\n",
    "inp = Input(shape=(2, 3))\n",
    "# Create the TimeDistributed layer (the output of the Dense layer)\n",
    "dense_time = keras.layers.TimeDistributed(keras.layers.Dense(3, activation='softmax', kernel_initializer=init, bias_initializer=init))\n",
    "pred = dense_time(inp)\n",
    "model = Model(inputs=inp, outputs=pred)\n",
    "\n",
    "y = model.predict(x)\n",
    "# Get the most probable class for each sample\n",
    "classes = np.argmax(y, axis=-1)\n",
    "for t in range(2):\n",
    "  # Get the t-th time-dimension slice of y and classes\n",
    "  for n, p, c in zip(names[t], y[:, t, :], classes[:, t]):\n",
    "  \tprint(\"Game {}: {} has probs {} and wins {}\\n\".format(t+1,n,p,prizes[c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Implementing the Full Encoder/Decoder Model\n",
    "\n",
    "still need a top part of the decoder.  \n",
    "implement this with a `TimeDistributed` & `Dense` layer\n",
    "\n",
    "![](encoder_decoder.png)  \n",
    "\n",
    "Implementing the full model:  \n",
    "\n",
    "    # The softmax prediction layer\n",
    "    de_dense = keras.layers.Dense( fr_vocab_size, activation='softmax' )\n",
    "    de_dense_time = keras.layers.TimeDistributed( de_dense )\n",
    "    de_pred = de_seq_dense( de_out )\n",
    "    \n",
    "    # Defining the full model\n",
    "    nmt = keras.models.Model( inputs = en_inputs, outputs = de_pred )\n",
    "    \n",
    "    # Compiling the model\n",
    "    nmt.compile( optimizer='adam', loss='categorical_crossentropy`, metrics['acc'])\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (None, 20, 357)\n"
     ]
    }
   ],
   "source": [
    "# Import Dense and TimeDistributed layers\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "# Define a softmax dense layer that has fr_vocab outputs\n",
    "de_dense = Dense(fr_vocab_size, activation='softmax')\n",
    "# Wrap the dense layer in a TimeDistributed layer\n",
    "de_dense_time = TimeDistributed(de_dense)\n",
    "# Get the final prediction of the model\n",
    "de_pred = de_dense_time(gru_outputs)\n",
    "print(\"Prediction shape: \", de_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 15, 150)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     [(None, 48), (None,  28800       input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 20, 48)       0           gru_5[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_6 (GRU)                     (None, 20, 48)       14112       repeat_vector_2[0][0]            \n",
      "                                                                 gru_5[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 20, 357)      17493       gru_6[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 60,405\n",
      "Trainable params: 60,405\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "# Define a model with encoder input and decoder output\n",
    "nmt = Model(inputs=en_inputs, outputs=de_pred)\n",
    "\n",
    "# Compile the model with an optimizer and a loss\n",
    "nmt.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# View the summary of the model \n",
    "nmt.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
