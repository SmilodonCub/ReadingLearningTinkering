{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e27da6d9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Learning Spark\n",
    "\n",
    "notes for Damji, Jules S., et al. Learning Spark. O'Reilly Media, 2020.\n",
    "\n",
    "*Simple things should be simple, complex things should be possible.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627e8403",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1) Introduction to Apache Spark: A Unified Analytics Engine\n",
    "\n",
    "Spark: bring in ideas borrowed from Hadoop MapReduce, but enhance the system: make it highly fault tolerant and embarrassingly parallel, support in-memory storage for intermediate results between iterative and interactive map and reduce computations, offer easy and composable APIs in multiple languages as a programming model, and support other workloads in a unified manner.  \n",
    "\n",
    "**Apache Spark** - a unified enginedesigned for large-sclae distributed data processing, onn premises in data centers or in the cloud\n",
    "\n",
    "* Speed\n",
    "    - a framework optimized to take advantage of hardware advancements\n",
    "    - highly parallel across workers on the cluster\n",
    "    - whole-stage code generation\n",
    "* Ease of Use\n",
    "    - provides a fundamental abstraction of a data structure over which higher level abstractions (dataframes) can be made\n",
    "* Modularity\n",
    "    - Spark operations can be applied across many types of workloads and expressed in many supported languages\n",
    "* Extensibility\n",
    "    - read from many sources and process in memory\n",
    "    - extend to read data from other sources ex S3\n",
    "    \n",
    "### Unified Analytics\n",
    "a unified stack of components that addresses diverse workloads under a single distributed fast engine\n",
    "\n",
    "#### Spark Components as a Unified Stack\n",
    "* Spark SQL - works well with structured data. combine SQL-like queries to query the data just read into a Spark DataFrame\n",
    "* Spark MLlib - a library containing common machine learning algorithms\n",
    "    - allows you to extrant or transform features, build pipelines and persist models during deployment\n",
    "* GraphX - a library for manipulating graphs and performing graph-parallel computations\n",
    "* Spark Structured Streaming - combine and react in real time to both static data and streaming data from engines\n",
    "\n",
    "#### Apache Spark's Distributed Execution\n",
    "Components of Spark's distributed architecture\n",
    "* Spark driver - responsible for instantiating a `SparkSession`\n",
    "* `SparkSession` - unified conduit to all Spark operations and data (...) makes working with Spark simpler and easier. A unified entry point to all of Spark's functionality\n",
    "* Cluster manager - manages and allocates resources for the cluster of nodes\n",
    "* Spark executer - runs on each worker node in a cluster and is responsible for executing tasks on the worker\n",
    "* Deployment modes - the cluster manager is agnostic to where it runs, so Spark can be deployed in multiple environments inn different modes\n",
    "     - modes: Local, Standalone, YARN (cluster/client), Kubernetes\n",
    "* Distributed data and partitions - a distributed scheme of breaking up data into chunks or partitions allows Spark executors to process only data that is close to them, minimizing network bandwidth\n",
    "\n",
    "### The Developer's Experience\n",
    "easy to use APIs for operating on small to large data sets across languages\n",
    "\n",
    "### Who uses Spark, and for What?\n",
    "\n",
    "* Data Science tasks - wranggle and transform data. also use established classification, regression and clustering algorithms for building models\n",
    "* Data Engineering tasks - build complex data pipelines that enable data ETL from both real-time ad static data sources. simple ways to parallelize computations and hide all the complexity of distribution and fault tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6101b7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9216e4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234d8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf728d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
