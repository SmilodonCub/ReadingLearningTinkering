{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb94daf2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# 🤗 HuggingFace Course\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a008030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c8cca8",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 🤗 Transformer Models\n",
    "\n",
    "Transformers, why are they so damn cool?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2559dba4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Introduction\n",
    "\n",
    "* Chapters 1-4: introduction of the main concepts of 🤗 Transformers library\n",
    "* Chapters 5-8: teach the basics of 🤗 Datasets and 🤗 Tokenizers + some intro to NLP'\n",
    "* Chapters 9-12: deeper dive to showcase specialized architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca9316",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Natural Language Processing\n",
    "\n",
    "**NLP**  \n",
    "a list of common tasks:  \n",
    "* classifying whole sentences - sentiment, classification (spam), grammer, etc.\n",
    "* classifying words in a sentence - grammer, POS, entities\n",
    "* generating text content - filling in blacks, sentence completion\n",
    "* extracting an answer form text - given a question + content, find answer\n",
    "* generating a new sentence from text input - summarizing text, translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e439a",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Tranformers, what can they do?\n",
    "\n",
    "The 🤗 Transformers library provides the functionality to create and use hosted models. The Model Hub contains many thousands of pretrained models that anyone can download and use.  \n",
    "\n",
    "#### Working with `pipelines`\n",
    "\n",
    "`pipelines` connect a model with it's necessary preprocessing and postprocessing steps\n",
    "1. the text is preprocessed into a format the model can understand\n",
    "2. the preprocessed inputs are passed to the model\n",
    "3. the predictions of the model are post-processed, so you can make sense of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c9fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0b7bf53fc7446f9d64ab9874ee193d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ddc5cd41a84d5eae7064b06e45d3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "669cd712c71441e2be8ad98560a3cae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ecb35d763049468afc9a56d64c184b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.8835864663124084}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline( \"sentiment-analysis\" )\n",
    "# also available: feature-extraction, fill-mask, named entity recognition, questions-answering,\n",
    "#                 summarization, text-generation, translation, zero-shot classification\n",
    "classifier( \"I've been waiting for a HuggingFace course since last Spring\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d80d546",
   "metadata": {},
   "source": [
    "**Note** - the model is cached, $\\therefore$ it does not need to be loaded when calling the pipeline object again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a96fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996492862701416}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier( \"I'm really excited to take this HuggingFace course\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d59151",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Taking a look at a few other pipelines:  \n",
    "\n",
    "#### Zero-Shot Classfication\n",
    "\n",
    "classifying texts that have not been labeled. allows you to specify which labels to use for the classification, so that you don't need to rely on the labels of the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146fdefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cebe0a4229b64989a20c0c59b511e00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f938cbbd3d1b47c0885f31093a06dff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357e2839b4fc49a9884e31b2e1a4c124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9e18fc9c64248e5a3efe8e9af07ae56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a7c3a2762241d0ab72f69986d58e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83284da09c724c168ff2844a41b3e9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'These are my notes from the HuggingFace online course',\n",
       " 'labels': ['education', 'entertainment', 'science', 'politics'],\n",
       " 'scores': [0.6758780479431152,\n",
       "  0.21396446228027344,\n",
       "  0.08056329190731049,\n",
       "  0.029594212770462036]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline( \"zero-shot-classification\" )\n",
    "classifier( \n",
    "    \"These are my notes from the HuggingFace online course\",\n",
    "    candidate_labels = ['education', 'science', 'politics', 'entertainment']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7351e11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'NASA’s James Webb Space Telescope team fully deployed its 21-foot, gold-coated primary mirror, successfully completing the final stage of all major spacecraft deployments to prepare for science operations.',\n",
       "  'labels': ['science', 'education', 'entertainment', 'politics'],\n",
       "  'scores': [0.972022294998169,\n",
       "   0.011234794743359089,\n",
       "   0.010500448755919933,\n",
       "   0.006242458242923021]},\n",
       " {'sequence': 'The world’s largest and most complex space science telescope will now begin moving its 18 primary mirror segments to align the telescope optics.',\n",
       "  'labels': ['science', 'entertainment', 'education', 'politics'],\n",
       "  'scores': [0.9860273599624634,\n",
       "   0.005517215467989445,\n",
       "   0.005045033525675535,\n",
       "   0.0034104110673069954]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier( [ 'NASA’s James Webb Space Telescope team fully deployed its 21-foot, gold-coated primary mirror, successfully completing the final stage of all major spacecraft deployments to prepare for science operations.',\n",
    "             'The world’s largest and most complex space science telescope will now begin moving its 18 primary mirror segments to align the telescope optics.'],\n",
    "          candidate_labels = ['education', 'science', 'politics', 'entertainment']\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f7df3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Text Generation\n",
    "\n",
    "provide a prompt and the model will auto-complete to generate the remaining text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b20420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 (https://huggingface.co/gpt2)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515c5b34190e4986b38ca5a42b66167a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256650a3baca483cb627a6b4dc39272b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/523M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81256e1da66442a787cbd52c0b52bf6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a231054450834a85be9a377babad0dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506ea0cd458e417ca7c3ce17f3277d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to understand the principles behind the two-sided nature of human being.'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline( 'text-generation' )\n",
    "generator( 'In this course, we will teach you how to understand' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bb963c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to understand and avoid some common'},\n",
       " {'generated_text': 'In this course, we will teach you how to understand the fundamentals of data'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator( 'In this course, we will teach you how to understand', num_return_sequences = 2, max_length = 15 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177fef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Seeing Slayer live was the greatest battle of the year (and probably of all time). It was so fierce that it was the'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest experience of all.\" After my introduction, Liu Yao glanced at me. \"We will be running'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest moment of their lives, and how they felt at that moment — their life that never ends —'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest fantasy that was left out in the world.\"\\n\\n\"And by the same token, if'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest accomplishment of her lives.\\n\\nShe had never used any supernatural powers before and could hardly feel'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator( 'Seeing Slayer live was the greatest', num_return_sequences = 5, max_length = 25 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f010636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb70915f4c1b4fe782fb731d102ddf4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9f437ec0b84742b8a41d1731756a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff4f485b17ac47598f7557d82407d73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/0.99M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bfb9e90b5a4a8a892e3d4d75a818bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d96a9a076e459cb275df1072020a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Seeing Slayer live was the greatest show of all time - in 1995, the television giant put back its plans, but that was'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest day in professional soccer history, with many leagues reaching huge financial heights. To qualify for the World'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest show ever released in Japan.\\n\\n\\n\\nThe Japanese version of Slayer premiered at the U'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest success in the world,” said the CEO of the agency.\\n\\n\\n\\n\\n'},\n",
       " {'generated_text': 'Seeing Slayer live was the greatest act of the show!\\nThe cast also talked about their experiences in New York, Los Angeles'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specifying a model from the Hub\n",
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "generator( 'Seeing Slayer live was the greatest', num_return_sequences = 5, max_length = 25 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d53d24",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Mask Filling\n",
    "\n",
    "fill in blanks in a given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722cb97f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base (https://huggingface.co/distilroberta-base)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897f7b935f7e4a41985608c23ed76139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf3e5fc92b840f1a3a83f44aa047426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/316M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9f713839054b57a18354120da851ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7303243e40394f3db1282e633ac51299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c14b04100845f580f058623b7b1bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This course will teach you all about mathematical models',\n",
       "  'score': 0.19631721079349518,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical'},\n",
       " {'sequence': 'This course will teach you all about building models',\n",
       "  'score': 0.04449249804019928,\n",
       "  'token': 745,\n",
       "  'token_str': ' building'},\n",
       " {'sequence': 'This course will teach you all about predictive models',\n",
       "  'score': 0.039371054619550705,\n",
       "  'token': 27930,\n",
       "  'token_str': ' predictive'},\n",
       " {'sequence': 'This course will teach you all about role models',\n",
       "  'score': 0.03575519099831581,\n",
       "  'token': 774,\n",
       "  'token_str': ' role'},\n",
       " {'sequence': 'This course will teach you all about business models',\n",
       "  'score': 0.027736075222492218,\n",
       "  'token': 265,\n",
       "  'token_str': ' business'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline( 'fill-mask' )\n",
    "unmasker( 'This course will teach you all about <mask> models', top_k=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d38f8288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5bd18dcc8774066b20d12512c9d2f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7ee0c1512d24da5aa70abdea262f4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/416M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a673ee18bf43efa676fceb8d7e6e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cee65613a515472f85bc7e7f9948e1bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f59cfb4fb542b3aba3fbefdb027399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'This course will teach you all about role models',\n",
       "  'score': 0.07605545967817307,\n",
       "  'token': 1648,\n",
       "  'token_str': 'role'},\n",
       " {'sequence': 'This course will teach you all about the models',\n",
       "  'score': 0.05633450299501419,\n",
       "  'token': 1103,\n",
       "  'token_str': 'the'},\n",
       " {'sequence': 'This course will teach you all about fashion models',\n",
       "  'score': 0.04619521275162697,\n",
       "  'token': 4633,\n",
       "  'token_str': 'fashion'},\n",
       " {'sequence': 'This course will teach you all about computer models',\n",
       "  'score': 0.030348550528287888,\n",
       "  'token': 2775,\n",
       "  'token_str': 'computer'},\n",
       " {'sequence': 'This course will teach you all about life models',\n",
       "  'score': 0.019965192303061485,\n",
       "  'token': 1297,\n",
       "  'token_str': 'life'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline( 'fill-mask', model = 'bert-base-cased' )\n",
    "unmasker( 'This course will teach you all about [MASK] models', top_k=5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81baa354",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Named Entity Recognition\n",
    "\n",
    "**NER** - find which parts of an input text correspond to entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a4ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74cae1d6ba2045dbad0ddd1866b66d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1af967d1514f55847eb8288ba20d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8084779330b242c7a2b7fb67c16a69e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3566ac2a3384257a61c4b1e67c28518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bonzilla/anaconda3/lib/python3.7/site-packages/transformers/pipelines/token_classification.py:129: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  f'`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"{aggregation_strategy}\"` instead.'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.99946195,\n",
       "  'word': 'Adams',\n",
       "  'start': 67,\n",
       "  'end': 72},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.99552476,\n",
       "  'word': 'CNN',\n",
       "  'start': 78,\n",
       "  'end': 81},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.8375926,\n",
       "  'word': 'State of the Union',\n",
       "  'start': 85,\n",
       "  'end': 103},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.99927413,\n",
       "  'word': 'Bernard Williams',\n",
       "  'start': 141,\n",
       "  'end': 157},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9963703,\n",
       "  'word': 'NYPD',\n",
       "  'start': 167,\n",
       "  'end': 171}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline( \"ner\", grouped_entities=True )\n",
    "ner( \"Let me be clear on this: My brother is qualified for the position, Adams told CNN’s 'State of the Union' when asked about making his sibling Bernard Williams a deputy NYPD commissioner.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d276e689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1be77ced98247588ee6c9b2a5ba77b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/326 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ca1e0e8aa5491bbcc2668d223dc1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/780k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b665bc8a3b41529fb9b9cf839c4bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f993cdcacd68488f86663ab8937d908e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2fc77cb91d48dd8d4650f0a73252b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218d035e76e541f2949b8579a29d2192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30cd778e719645e9807bd4d44a5a06eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'VERB',\n",
       "  'score': 0.9986479,\n",
       "  'word': ' Let',\n",
       "  'start': 1,\n",
       "  'end': 3},\n",
       " {'entity_group': 'PRON',\n",
       "  'score': 0.99980384,\n",
       "  'word': ' me',\n",
       "  'start': 4,\n",
       "  'end': 6},\n",
       " {'entity_group': 'AUX',\n",
       "  'score': 0.98620975,\n",
       "  'word': ' be',\n",
       "  'start': 7,\n",
       "  'end': 9},\n",
       " {'entity_group': 'ADJ',\n",
       "  'score': 0.9991356,\n",
       "  'word': ' clear',\n",
       "  'start': 10,\n",
       "  'end': 15},\n",
       " {'entity_group': 'ADP',\n",
       "  'score': 0.99943495,\n",
       "  'word': ' on',\n",
       "  'start': 16,\n",
       "  'end': 18},\n",
       " {'entity_group': 'PRON',\n",
       "  'score': 0.99961954,\n",
       "  'word': ' this',\n",
       "  'start': 19,\n",
       "  'end': 23},\n",
       " {'entity_group': 'PUNCT',\n",
       "  'score': 0.93715745,\n",
       "  'word': ':',\n",
       "  'start': 23,\n",
       "  'end': 24},\n",
       " {'entity_group': 'PRON',\n",
       "  'score': 0.99976885,\n",
       "  'word': ' My',\n",
       "  'start': 25,\n",
       "  'end': 27},\n",
       " {'entity_group': 'NOUN',\n",
       "  'score': 0.9995938,\n",
       "  'word': ' brother',\n",
       "  'start': 28,\n",
       "  'end': 35},\n",
       " {'entity_group': 'AUX',\n",
       "  'score': 0.99777746,\n",
       "  'word': ' is',\n",
       "  'start': 36,\n",
       "  'end': 38},\n",
       " {'entity_group': 'ADJ',\n",
       "  'score': 0.9990982,\n",
       "  'word': ' qualified',\n",
       "  'start': 39,\n",
       "  'end': 48},\n",
       " {'entity_group': 'ADP',\n",
       "  'score': 0.9997824,\n",
       "  'word': ' for',\n",
       "  'start': 49,\n",
       "  'end': 52},\n",
       " {'entity_group': 'DET',\n",
       "  'score': 0.9999352,\n",
       "  'word': ' the',\n",
       "  'start': 53,\n",
       "  'end': 56},\n",
       " {'entity_group': 'NOUN',\n",
       "  'score': 0.9997966,\n",
       "  'word': ' position',\n",
       "  'start': 57,\n",
       "  'end': 65},\n",
       " {'entity_group': 'PUNCT',\n",
       "  'score': 0.7442607,\n",
       "  'word': ',',\n",
       "  'start': 65,\n",
       "  'end': 66},\n",
       " {'entity_group': 'PROPN',\n",
       "  'score': 0.99950045,\n",
       "  'word': ' Adams',\n",
       "  'start': 67,\n",
       "  'end': 72},\n",
       " {'entity_group': 'VERB',\n",
       "  'score': 0.999692,\n",
       "  'word': ' told',\n",
       "  'start': 73,\n",
       "  'end': 77},\n",
       " {'entity_group': 'PROPN',\n",
       "  'score': 0.99951416,\n",
       "  'word': ' CNN',\n",
       "  'start': 78,\n",
       "  'end': 81},\n",
       " {'entity_group': 'DET',\n",
       "  'score': 0.82623136,\n",
       "  'word': '�',\n",
       "  'start': 81,\n",
       "  'end': 82},\n",
       " {'entity_group': 'PART',\n",
       "  'score': 0.9806938,\n",
       "  'word': '�',\n",
       "  'start': 81,\n",
       "  'end': 82},\n",
       " {'entity_group': 'ADP',\n",
       "  'score': 0.5717784,\n",
       "  'word': 's',\n",
       "  'start': 82,\n",
       "  'end': 83},\n",
       " {'entity_group': 'PUNCT',\n",
       "  'score': 0.9272147,\n",
       "  'word': \" '\",\n",
       "  'start': 84,\n",
       "  'end': 85},\n",
       " {'entity_group': 'NOUN',\n",
       "  'score': 0.71977973,\n",
       "  'word': 'State',\n",
       "  'start': 85,\n",
       "  'end': 90},\n",
       " {'entity_group': 'ADP',\n",
       "  'score': 0.9996913,\n",
       "  'word': ' of',\n",
       "  'start': 91,\n",
       "  'end': 93},\n",
       " {'entity_group': 'DET',\n",
       "  'score': 0.9996956,\n",
       "  'word': ' the',\n",
       "  'start': 94,\n",
       "  'end': 97},\n",
       " {'entity_group': 'PROPN',\n",
       "  'score': 0.6245964,\n",
       "  'word': ' Union',\n",
       "  'start': 98,\n",
       "  'end': 103},\n",
       " {'entity_group': 'PUNCT',\n",
       "  'score': 0.99572575,\n",
       "  'word': \"'\",\n",
       "  'start': 103,\n",
       "  'end': 104},\n",
       " {'entity_group': 'SCONJ',\n",
       "  'score': 0.9991322,\n",
       "  'word': ' when',\n",
       "  'start': 105,\n",
       "  'end': 109},\n",
       " {'entity_group': 'VERB',\n",
       "  'score': 0.9997819,\n",
       "  'word': ' asked',\n",
       "  'start': 110,\n",
       "  'end': 115},\n",
       " {'entity_group': 'SCONJ',\n",
       "  'score': 0.9990184,\n",
       "  'word': ' about',\n",
       "  'start': 116,\n",
       "  'end': 121},\n",
       " {'entity_group': 'VERB',\n",
       "  'score': 0.9998317,\n",
       "  'word': ' making',\n",
       "  'start': 122,\n",
       "  'end': 128},\n",
       " {'entity_group': 'PRON',\n",
       "  'score': 0.9997869,\n",
       "  'word': ' his',\n",
       "  'start': 129,\n",
       "  'end': 132},\n",
       " {'entity_group': 'NOUN',\n",
       "  'score': 0.99957514,\n",
       "  'word': ' sibling',\n",
       "  'start': 133,\n",
       "  'end': 140},\n",
       " {'entity_group': 'PROPN',\n",
       "  'score': 0.9996966,\n",
       "  'word': ' Bernard Williams',\n",
       "  'start': 141,\n",
       "  'end': 157},\n",
       " {'entity_group': 'DET',\n",
       "  'score': 0.99989897,\n",
       "  'word': ' a',\n",
       "  'start': 158,\n",
       "  'end': 159},\n",
       " {'entity_group': 'NOUN',\n",
       "  'score': 0.7097997,\n",
       "  'word': ' deputy',\n",
       "  'start': 160,\n",
       "  'end': 166},\n",
       " {'entity_group': 'PROPN',\n",
       "  'score': 0.99958587,\n",
       "  'word': ' NYPD',\n",
       "  'start': 167,\n",
       "  'end': 171},\n",
       " {'entity_group': 'NOUN',\n",
       "  'score': 0.5886441,\n",
       "  'word': ' commissioner.',\n",
       "  'start': 172,\n",
       "  'end': 185}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagging\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vblagoje/roberta-base-english-upos\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"vblagoje/roberta-base-english-upos\")\n",
    "ner = pipeline( \"ner\", model = model, tokenizer=tokenizer, grouped_entities=True )\n",
    "ner( \"Let me be clear on this: My brother is qualified for the position, Adams told CNN’s 'State of the Union' when asked about making his sibling Bernard Williams a deputy NYPD commissioner.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5ead2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36de1de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad (https://huggingface.co/distilbert-base-cased-distilled-squad)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.38330498337745667, 'start': 45, 'end': 53, 'answer': 'Brooklyn'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_answering = pipeline( 'question-answering' )\n",
    "q_answering( \n",
    "    question = 'Where does Zach work?',\n",
    "    context = 'Zach is a bike messenger in NYC and lives in Brooklyn'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22818099",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Summarization\n",
    "\n",
    "distilling text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ff8822b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f447513a784c538621113b85851fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6039721128b742a79a35265efe4deeab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edf7e3624c041208f899b9491fc7bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a760f97d6e284de683f35b41dfcfa528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb672ba76d846049ed84bfde36bcfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The Witcher is a fantasy drama based on the book series of the same name by Polish writer Andrzej Sapkowski . Set on a fictional, medieval-inspired landmass known as \"the Continent\", The Witcher explores the legend of Geralt of Rivia and Princess Ciri, who are linked to each other by destiny . The first season consisted of eight episodes and was released on Netflix in its entirety on December 20, 2019 .'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline( 'summarization' )\n",
    "summarizer( \"\"\"The Witcher is a fantasy drama streaming television series created by Lauren Schmidt Hissrich, fan fiction based on the book series of the same name by Polish writer Andrzej Sapkowski. Set on a fictional, medieval-inspired landmass known as \"the Continent\", The Witcher explores the legend of Geralt of Rivia and Princess Ciri, who are linked to each other by destiny. It stars Henry Cavill, Freya Allan and Anya Chalotra.\n",
    "\n",
    "The first season consisted of eight episodes and was released on Netflix in its entirety on December 20, 2019. It was based on The Last Wish and Sword of Destiny, which are collections of short stories that precede the main Witcher saga. The second season, consisting of eight episodes, was released on December 17, 2021. In September 2021, Netflix renewed the series for a third season. An animated origin story film, The Witcher: Nightmare of the Wolf, was released on August 23, 2021, while a prequel miniseries, The Witcher: Blood Origin, will be released in 2022.\n",
    "\n",
    "The story begins by following three main characters: the witcher Geralt of Rivia; crown princess Cirilla of Cintra; and the sorceress Yennefer of Vengerberg, meeting them at different points in time. A witcher is a human trained and magically mutated since childhood to be strong and resilient enough to fight the many monsters that plague The Continent. The first season bounces the viewer back and forth in time, exploring formative events that shape the main characters before eventually merging into a single timeline.\n",
    "\n",
    "Yennefer and Geralt encounter each other several times across many decades, as both are magic-users with unnaturally long lives. They clash more than once and are on-and-off lovers, both of them longing for more but afraid to admit it.\n",
    "\n",
    "Meanwhile, Geralt and princess Cirilla are linked by destiny before she is born: for saving her father's life, Geralt elected to be paid by invoking \"the Law of Surprise\", a custom in which the one who was saved gives his savior the next thing he learns that he possesses, but did NOT know about at the time his life was saved. After promising Geralt the surprise, Cirilla's father Duny learns that his bride is pregnant. Thus, the unborn princess Ciri was bound to the witcher in an unbreakable pact of destiny. Geralt wants nothing to do with a child and goes on his solitary way. After the two finally meet, when the 12-year-old princess has been orphaned by war, the witcher becomes her protector; he must keep her safe and fight against many pursuers to prevent Ciri's powerful magic from being used to destroy the world.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29c502",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e34a6cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by HuggingFace'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = pipeline( 'translation', model = 'Helsinki-NLP/opus-mt-fr-en' )\n",
    "translator('Ce cours est produit par HuggingFace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5305bc3",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### How do Transformers work?\n",
    "\n",
    "Transformers were introduced in June 2017  \n",
    "They can be broadly grouped into 3 categories: \n",
    "* GPT-like - autoregressive\n",
    "* BERT-like - autoencoding\n",
    "* BART/T5-like - seq2seq \n",
    "\n",
    "These models learned language by **self-supervised learning** - automatically compute from inputs to the model to develop a statistical understanding of the language.  \n",
    "Transformers models are very broad and not very useful for specific tasks. However, they can be used as a base case and be fine-tuned using supervised learning for a specific task == **transfer learning**  \n",
    "\n",
    "\n",
    "Large Models have a big carbon footprint  \n",
    "Several things to consider:\n",
    "* use pretrained models when they are available\n",
    "* use fine-tuning vs. from scratch\n",
    "* starting with smaller experiments and then debugging\n",
    "* doing literature review to choose hyperparameter ranges\n",
    "* random seach vs grid search\n",
    "\n",
    "[**Machine Learning Emissions Calculator**](https://mlco2.github.io/impact/)  \n",
    "also codecarbon  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c50e2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class EmissionsTracker in module codecarbon.emissions_tracker:\n",
      "\n",
      "class EmissionsTracker(BaseEmissionsTracker)\n",
      " |  EmissionsTracker(project_name: str = 'codecarbon', measure_power_secs: int = 15, output_dir: str = '.', save_to_file: bool = True, gpu_ids: Union[List, NoneType] = None, emissions_endpoint: Union[str, NoneType] = None, co2_signal_api_token: Union[str, NoneType] = None)\n",
      " |  \n",
      " |  An online emissions tracker that auto infers geographical location,\n",
      " |  using `geojs` API\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      EmissionsTracker\n",
      " |      BaseEmissionsTracker\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseEmissionsTracker:\n",
      " |  \n",
      " |  __init__(self, project_name: str = 'codecarbon', measure_power_secs: int = 15, output_dir: str = '.', save_to_file: bool = True, gpu_ids: Union[List, NoneType] = None, emissions_endpoint: Union[str, NoneType] = None, co2_signal_api_token: Union[str, NoneType] = None)\n",
      " |      :param project_name: Project name for current experiment run, default name\n",
      " |                           as \"codecarbon\"\n",
      " |      :param measure_power_secs: Interval (in seconds) to measure hardware power\n",
      " |                                 usage, defaults to 15\n",
      " |      :param output_dir: Directory path to which the experiment details are logged\n",
      " |                         in a CSV file called `emissions.csv`, defaults to current\n",
      " |                         directory\n",
      " |      :param save_to_file: Indicates if the emission artifacts should be logged to a\n",
      " |                           file, defaults to True\n",
      " |      :param gpu_ids: User-specified known gpu ids to track, defaults to None\n",
      " |      :param emissions_endpoint: Optional URL of http endpoint for sending emissions data\n",
      " |      :param co2_signal_api_token: API token for co2signal.com (requires sign-up for free beta)\n",
      " |  \n",
      " |  start(self) -> None\n",
      " |      Starts tracking the experiment.\n",
      " |      Currently, Nvidia GPUs are supported.\n",
      " |      :return: None\n",
      " |  \n",
      " |  stop(self) -> Union[float, NoneType]\n",
      " |      Stops tracking the experiment\n",
      " |      :return: CO2 emissions in kgs\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseEmissionsTracker:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pip install codecarbon\n",
    "from codecarbon import EmissionsTracker\n",
    "help( EmissionsTracker )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6093ff2",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Sharing language models is paramount: sharing the trained weights and building on top of already trained weights reduces the overall compute cost and carbon footprint of the community.  \n",
    "\n",
    "#### Transfer Learning\n",
    "\n",
    "Leverage the knowledge gained from training a model on a very large dataset on another task.  \n",
    "Initialize a model with the same weights as a pretrained model, thus transfering the knowledge.  \n",
    "**pre-training** - the act of trainign a model from scratch: the weights are started at random and the training starts without any prior knowledge. pre-training si usually done on very large training data sets.  \n",
    "**fine-tuning** - training done after a model has been pretrained typically with a comparatively smaller dataset  \n",
    "\n",
    "fine-tuning has lower time, data, financial and environmental costs. However, the resulting model inherits any bias present from the pretrained model.  \n",
    "\n",
    "#### General Archtecture\n",
    "\n",
    "* **Encoder** - acquires and interprets input: receives input and builds representation of its features\n",
    "* **Decoder** - generates output: ises the encoder's representation (features) along with other inputs to generate a target sequence\n",
    "* Types of Models:\n",
    "    * **Encoder-only models** - tasks for understanding the input (classification, NER)\n",
    "    * **Decoder-only models** - generative tasks (text generation)\n",
    "    * **Encoder-decoder models** - Sequence-to-sequence models; good for generative tasks that require an input (translation, summarization)\n",
    "* **Attention Layers** - tells the model to pay specific attention to certain words in the sentence it was passed; a word by itself has meaning, but that meaning is deeply affected by the context, which can be any other word (or words) before or after the wordbeing studied.  \n",
    "* **Architecture** - the skeleton of the model\n",
    "* **Checkpoints** - the weights that will be lloaded by a given architecture\n",
    "* **Model** - umbrella term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1ee1c",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Encoder Models\n",
    "\n",
    "* Encoder models use only the encoder of a Transformer model\n",
    "* **feature vector/tensor** - holds the meaning of the word within the text. retrieves a numerical vector representation of each word with dimensions defined by the architecture of the model. each numerical representation is contexualized: each word in the initial sequence affects every word's representation\n",
    "* **\"Bi-directional\" attention** - the vectorization takes into account tokens both befor and after\n",
    "* **auto-encoding models**\n",
    "* Examples: \n",
    "    - ALBERT\n",
    "    - BERT\n",
    "    - DistilBERT\n",
    "    - ELECTRA\n",
    "    - RoBERTa\n",
    "* When to use an Encoder Model:\n",
    "    - sequence classification (sentiment analysis), question answering, masked language modeling\n",
    "    - NLU: Natural Language Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e2b8f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Decoder Models\n",
    "\n",
    "* Decoder Models use only the Decoder of a Transformer Model\n",
    "* **Auto-regressive** - attention layers can only access the words positioned before it in a sentence\n",
    "* **feature vector/tensor** - one vector per word with length determined by the model architecture differs from Encoder models by its self attention mechnanism\n",
    "* **masked self-attention** - the tokens to the right or left of the word are masked; feature vector is decided by one-directional context\n",
    "* best suited for text generation tasks\n",
    "* Examples:\n",
    "    - CTRL\n",
    "    - GPT\n",
    "    - GPT-2\n",
    "    - Transformer XL\n",
    "* when to use Decoder Model:\n",
    "    - Causal Language Modeling: great at generational tests: generating sequences of text\n",
    "    - NLG: Natural Language Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a4569b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Sequence-to-sequence Models\n",
    "\n",
    "* Encoder-Decoder Models use both parts of the Transformers architecture.\n",
    "* Works by:\n",
    "    - takes the numerical representation from the Encoder (meaning of the sequence)\n",
    "    - pass to the Decoder along with a token to start a sequence\n",
    "    - the Decoder will try to sequencially decode the Encoder's output as a 'word'\n",
    "    - Decoder works in a auto-regressive way to add tokens until a stop is encountered\n",
    "* Are best for tasks revolving around generation of new text which depends on context: \n",
    "    - summarization\n",
    "    - traslation\n",
    "    - generative question answering\n",
    "* Examples: \n",
    "    - BART\n",
    "    - Marian\n",
    "    - T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3203f",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Bias and limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448636b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ceeb9",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### End of Chapter Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b245a56",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## Using 🤗 Transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
